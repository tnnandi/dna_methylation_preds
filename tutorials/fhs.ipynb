{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ðŸ§¬ âš™ï¸ CpGPT Quick Setup Tutorial âš™ï¸ ðŸ§¬\n",
    "\n",
    "Welcome to the CpGPT Quick Setup Tutorial! ðŸ‘‹ \n",
    "\n",
    "In this notebook, we'll walk you through the fastest way of using CpGPT for your research.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup Environment](#1-setup-environment)\n",
    "2. [Retrieve DNA LLM Embeddings](#2-retrieve-dna-llm-embeddings)\n",
    "3. [Download and Load Model](#3-download-and-load-model)\n",
    "4. [Prepare Data Objects](#4-prepare-data-objects)\n",
    "5. [Run Inference](#5-run-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "We'll import the necessary Python packages and set up our environment for CpGPT. We'll be using a mix of standard data science libraries and CpGPT-specific modules. We'll also set some important variables that will be used throughout the notebook. Pay attention to these as you may need to adjust them based on your specific setup and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Directory paths\n",
    "DEPENDENCIES_DIR = \"../dependencies\"\n",
    "LLM_DEPENDENCIES_DIR = DEPENDENCIES_DIR + \"/human\"\n",
    "DATA_DIR = \"../data\"\n",
    "PROCESSED_DIR = \"../data/tutorials/processed/fhs_setup\"\n",
    "\n",
    "MODEL_NAME = \"age\" #\"cancer\"\n",
    "MODEL_CHECKPOINT_PATH = f\"../dependencies/model/weights/{MODEL_NAME}.ckpt\"\n",
    "MODEL_CONFIG_PATH = f\"../dependencies/model/config/{MODEL_NAME}.yaml\"\n",
    "MODEL_VOCAB_PATH = f\"../dependencies/model/vocab/{MODEL_NAME}.json\"\n",
    "\n",
    "# ARROW_DF_PATH = \"../data/cpgcorpus/raw/GSE182215/GPL13534/betas/QCDPB.arrow\"\n",
    "ARROW_DF_FILTERED_PATH = \"../data/tutorials/raw/fhs_filtered.arrow\"\n",
    "\n",
    "# The maximum context length to give to the model\n",
    "MAX_INPUT_LENGTH = 20_000 # you might wanna go higher hardware permitting\n",
    "MAX_ATTN_LENGTH = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **âš ï¸ Warning**\n",
    "> \n",
    "> It is recommended to have a GPU for inference as CPU might be slow.\n",
    "> \n",
    "> Reconstructing the methylome for a few hundred samples might take up to one hour on a CPU. âŒ›\n",
    ">\n",
    "> This might be a great exercise in testing your patience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyaging as pya\n",
    "import seaborn as sns\n",
    "\n",
    "# Lightning imports\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "# cpgpt-specific imports\n",
    "from cpgpt.data.components.cpgpt_datasaver import CpGPTDataSaver\n",
    "from cpgpt.data.cpgpt_datamodule import CpGPTDataModule\n",
    "from cpgpt.trainer.cpgpt_trainer import CpGPTTrainer\n",
    "from cpgpt.data.components.dna_llm_embedder import DNALLMEmbedder\n",
    "from cpgpt.data.components.illumina_methylation_prober import IlluminaMethylationProber\n",
    "from cpgpt.infer.cpgpt_inferencer import CpGPTInferencer\n",
    "from cpgpt.model.cpgpt_module import m_to_beta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_everything(RANDOM_SEED, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve DNA LLM Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the DNA LLM Embeddings, there are two options:\n",
    "- download the dependencies with all of the sequence embeddings for the CpG sites targeted by the Illumina arrays;\n",
    "- generate from scratch using the DNA LLM directly for loci outside of the ones already available for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mInitializing class CpGPTInferencer.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing device: cpu.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing dependencies directory: ../dependencies\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing data directory: ../data\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mThere are 19 CpGPT models available such as age, age_cot, average_adultweight, boa, cancer, clock_proxies, diseases, epicvmammal, hannum, hannum_cot, human_rrbs_atlas, large, mammalian, maximum_lifespan, mortality, proteins, relative_age, scimetv3, small, etc.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mThere are 2089 GSE datasets available such as GSE100184, GSE100208, GSE100209, etc.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First let's declare the inferencer\n",
    "inferencer = CpGPTInferencer(dependencies_dir=DEPENDENCIES_DIR, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cpgpt.infer.cpgpt_inferencer.CpGPTInferencer at 0x7f503271d9d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Download Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The already-processed dependencies contain the sequence embeddings for both human (`s3://cpgpt-lucascamillo-public/dependencies/human`) and several mammalian species (`s3://cpgpt-lucascamillo-public/dependencies/mammalian`). Here, let's use the human as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mDependencies for human already exist at ../dependencies/human (skipping download).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inferencer.download_dependencies(species=\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate DNA LLM Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate genomic embeddings for loci outside of the ones already available for download, we can use the `DNALLMEmbedder` class. We need the loci in a list with the following format from ENSEMBL: 'chromosome:position'. Be mindful as this function can take a long time to run dependending on your GPU. For instance, embeddings ~1M genomic loci from the Illumina arrays takes about 12h in an RTX 4090."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LLM_DEPENDENCIES_DIR):\n",
    "\n",
    "    # List CpG genomic locations\n",
    "    example_genomic_locations = ['1:100000', '1:250500', 'X:2031253']\n",
    "\n",
    "    # Declare required class\n",
    "    embedder = DNALLMEmbedder(dependencies_dir=LLM_DEPENDENCIES_DIR)\n",
    "\n",
    "    # Parse the embeddings\n",
    "    embedder.parse_dna_embeddings(\n",
    "        example_genomic_locations,\n",
    "        \"homo_sapiens\",\n",
    "        dna_llm=\"nucleotide-transformer-v2-500m-multi-species\",\n",
    "        dna_context_len=2001,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please first check the model zoo for the available models and their corresponding features on the README.md file. To load any given model, you first need to define the dictionary structure with the hyperparameters and use the `CpGPTInferencer` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Download Checkpoint and Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mModel checkpoint already exists at ../dependencies/model/weights/age.ckpt (skipping download).\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mModel config already exists at ../dependencies/model/config/age.yaml (skipping download).\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mModel vocabulary already exists at ../dependencies/model/vocab/age.json (skipping download).\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mSuccessfully downloaded model 'age'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Download the checkpoint and configuration files\n",
    "inferencer.download_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mLoaded CpGPT model config.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mInstantiated CpGPT model from config.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing device: cpu.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mLoading checkpoint from: ../dependencies/model/weights/age.ckpt\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mCheckpoint loaded into the model.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the model configuration\n",
    "config = inferencer.load_cpgpt_config(MODEL_CONFIG_PATH)\n",
    "\n",
    "# Load the model weights\n",
    "model = inferencer.load_cpgpt_model(\n",
    "    config,\n",
    "    model_ckpt_path=MODEL_CHECKPOINT_PATH,\n",
    "    strict_load=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CpGPTLitModule(\n",
       "  (net): CpGPT(\n",
       "    (position_encoder): RotaryPositionalEmbeddings()\n",
       "    (absolute_position_encoder): AbsolutePositionalEncoding(\n",
       "      (dropout): Dropout(p=0.01, inplace=False)\n",
       "    )\n",
       "    (dna_encoder): MLPBlock(\n",
       "      (input_norm): Identity()\n",
       "      (input_adapter): Linear(in_features=1024, out_features=128, bias=True)\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x Sequential(\n",
       "          (0): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (1): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Dropout(p=0.01, inplace=False)\n",
       "          (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (output_norm): Identity()\n",
       "      (output_adapter): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (meth_encoder): MLPBlock(\n",
       "      (input_norm): Identity()\n",
       "      (input_adapter): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (blocks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (1): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Dropout(p=0.01, inplace=False)\n",
       "          (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (output_norm): Identity()\n",
       "      (output_adapter): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerPPBlock(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (dropout_mlp): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (norm1_cls): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (norm1_seq): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (norm2_cls): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (norm2_seq): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (dropout_sa): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_ff): Dropout(p=0.0, inplace=False)\n",
       "          (activation): SwiGLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (meth_decoder): MLPBlock(\n",
       "      (input_norm): Identity()\n",
       "      (input_adapter): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x Sequential(\n",
       "          (0): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (1): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Dropout(p=0.01, inplace=False)\n",
       "          (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (output_norm): Identity()\n",
       "      (output_adapter): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (meth_unc_decoder): MLPBlock(\n",
       "      (input_norm): Identity()\n",
       "      (input_adapter): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x Sequential(\n",
       "          (0): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (1): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Dropout(p=0.01, inplace=False)\n",
       "          (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (output_norm): Identity()\n",
       "      (output_adapter): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (condition_tokens): ParameterList(  (0): Parameter containing: [torch.float32 of size 1x128])\n",
       "    (condition_decoder): MLPBlock(\n",
       "      (input_norm): Identity()\n",
       "      (input_adapter): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x Sequential(\n",
       "          (0): RMSNorm((128,), eps=None, elementwise_affine=True)\n",
       "          (1): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (2): SwiGLU()\n",
       "          (3): Dropout(p=0.01, inplace=False)\n",
       "          (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (output_norm): Identity()\n",
       "      (output_adapter): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (train_loss): MeanMetric()\n",
       "  (val_loss): MeanMetric()\n",
       "  (test_loss): MeanMetric()\n",
       "  (val_loss_best): MinMetric()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Prepare Data Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform inference, we need to prepare the data objects, which are essentially memory-mapped versions for faster loading. As an example, let's download a toy dataset from the _CpGCorpus_ database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 load FHS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/grand/GeomicVar/tarak/cpgpt/CpGPT/data_kirmani\"\n",
    "data_dir = os.path.join(root_dir, \"phg001091.v5.FHS_DNAMethylation.methylation-data-matrixfmt.c1\")\n",
    "\n",
    "# Load the parquet file\n",
    "# The CSV file is too large to load into memory, so we will use a parquet file instead (converted from CSV using convert_csv_to_parquet.py)\n",
    "parquet_file = os.path.join(data_dir, \"gen3_methylation_c1.parquet\")\n",
    "df = pd.read_parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metadata from Yash\n",
    "metadata_df = pd.read_csv(\"/grand/GeomicVar/tarak/methylGPT/data_kirmani/fhs_chip_metadata_yp_05092025.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>AgeAtBloodDraw</th>\n",
       "      <th>sex</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>haschip</th>\n",
       "      <th>Gene</th>\n",
       "      <th>ExonicFunc</th>\n",
       "      <th>VAF</th>\n",
       "      <th>chip_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWD101503</td>\n",
       "      <td>11465</td>\n",
       "      <td>63.503015</td>\n",
       "      <td>F</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>-0.011618</td>\n",
       "      <td>-0.007526</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>splicing</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWD122068</td>\n",
       "      <td>17510</td>\n",
       "      <td>71.623647</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>nonsynonymous SNV</td>\n",
       "      <td>0.121</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWD125867</td>\n",
       "      <td>3253</td>\n",
       "      <td>56.318747</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>-0.001669</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>frameshift insertion</td>\n",
       "      <td>0.094</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWD126946</td>\n",
       "      <td>5657</td>\n",
       "      <td>73.918013</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>frameshift deletion</td>\n",
       "      <td>0.161</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWD143985</td>\n",
       "      <td>9868</td>\n",
       "      <td>76.798292</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>splicing</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>NWD995511</td>\n",
       "      <td>22904</td>\n",
       "      <td>76.888642</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>-0.001642</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>NWD995734</td>\n",
       "      <td>24905</td>\n",
       "      <td>64.064286</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>NWD998499</td>\n",
       "      <td>10703</td>\n",
       "      <td>64.028693</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>NWD998833</td>\n",
       "      <td>21202</td>\n",
       "      <td>69.394991</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.001616</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>NWD709135</td>\n",
       "      <td>7114</td>\n",
       "      <td>60.524172</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>-0.000794</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1944 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sample  subject_id  AgeAtBloodDraw sex       PC1       PC2       PC3  \\\n",
       "0     NWD101503       11465       63.503015   F  0.001995 -0.000976 -0.000891   \n",
       "1     NWD122068       17510       71.623647   F  0.002355 -0.001631 -0.000852   \n",
       "2     NWD125867        3253       56.318747   F  0.002322 -0.001669 -0.000809   \n",
       "3     NWD126946        5657       73.918013   F  0.002306 -0.001581 -0.000887   \n",
       "4     NWD143985        9868       76.798292   F  0.002263 -0.001670 -0.000842   \n",
       "...         ...         ...             ...  ..       ...       ...       ...   \n",
       "1939  NWD995511       22904       76.888642   F  0.002305 -0.001642 -0.000772   \n",
       "1940  NWD995734       24905       64.064286   M  0.002358 -0.001689 -0.000774   \n",
       "1941  NWD998499       10703       64.028693   F  0.002350 -0.001710 -0.000661   \n",
       "1942  NWD998833       21202       69.394991   M  0.002340 -0.001616 -0.000801   \n",
       "1943  NWD709135        7114       60.524172   M  0.002300 -0.001686 -0.000794   \n",
       "\n",
       "           PC4       PC5       PC6       PC7       PC8       PC9      PC10  \\\n",
       "0    -0.005666 -0.011618 -0.007526  0.000804 -0.003980 -0.002093  0.004659   \n",
       "1     0.001525  0.002503 -0.000561  0.000437 -0.000893  0.000159  0.001559   \n",
       "2     0.000380  0.001179  0.000148 -0.000927 -0.000341  0.001978 -0.000106   \n",
       "3     0.001144  0.001952 -0.001457  0.001603 -0.000156 -0.008303 -0.004131   \n",
       "4    -0.000322 -0.000775  0.000953 -0.001219  0.000528  0.003866 -0.000707   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1939  0.000911  0.001931  0.000218 -0.000435 -0.000511  0.001944  0.001706   \n",
       "1940  0.001496  0.002349 -0.000174 -0.000610  0.000027  0.003265  0.003716   \n",
       "1941  0.001111  0.002059  0.000170 -0.000626 -0.000338  0.003814  0.004609   \n",
       "1942  0.001095  0.002020  0.000033 -0.000615 -0.000132  0.003422  0.003995   \n",
       "1943  0.000975  0.001990 -0.000069 -0.000594 -0.000415  0.002351  0.002392   \n",
       "\n",
       "          PC11  haschip    Gene            ExonicFunc    VAF  chip_binary  \n",
       "0    -0.001234        1  DNMT3A              splicing  0.170          1.0  \n",
       "1    -0.000292        1  DNMT3A     nonsynonymous SNV  0.121          1.0  \n",
       "2     0.000994        1  DNMT3A  frameshift insertion  0.094          1.0  \n",
       "3     0.000488        1  DNMT3A   frameshift deletion  0.161          1.0  \n",
       "4     0.001694        1  DNMT3A              splicing  0.174          1.0  \n",
       "...        ...      ...     ...                   ...    ...          ...  \n",
       "1939 -0.000293        0     NaN                   NaN    NaN          NaN  \n",
       "1940  0.001137        0     NaN                   NaN    NaN          NaN  \n",
       "1941 -0.000103        0     NaN                   NaN    NaN          NaN  \n",
       "1942  0.000849        0     NaN                   NaN    NaN          NaN  \n",
       "1943  0.000887        0     NaN                   NaN    NaN          NaN  \n",
       "\n",
       "[1944 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3630</th>\n",
       "      <th>10226</th>\n",
       "      <th>22854</th>\n",
       "      <th>5641</th>\n",
       "      <th>13515</th>\n",
       "      <th>26098</th>\n",
       "      <th>4354</th>\n",
       "      <th>4892</th>\n",
       "      <th>8567</th>\n",
       "      <th>393</th>\n",
       "      <th>...</th>\n",
       "      <th>9791</th>\n",
       "      <th>24702</th>\n",
       "      <th>5833</th>\n",
       "      <th>1692</th>\n",
       "      <th>11354</th>\n",
       "      <th>5197</th>\n",
       "      <th>18255</th>\n",
       "      <th>2077</th>\n",
       "      <th>19268</th>\n",
       "      <th>1891</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probe.id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cg00455876</th>\n",
       "      <td>0.340616</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.279148</td>\n",
       "      <td>0.363048</td>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.341001</td>\n",
       "      <td>0.586655</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.354304</td>\n",
       "      <td>0.406437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318181</td>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.402250</td>\n",
       "      <td>0.542247</td>\n",
       "      <td>0.358957</td>\n",
       "      <td>0.407751</td>\n",
       "      <td>0.272390</td>\n",
       "      <td>0.430805</td>\n",
       "      <td>0.655632</td>\n",
       "      <td>0.391442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg01707559</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.128761</td>\n",
       "      <td>0.393184</td>\n",
       "      <td>0.331995</td>\n",
       "      <td>0.352611</td>\n",
       "      <td>0.371087</td>\n",
       "      <td>0.094050</td>\n",
       "      <td>0.317272</td>\n",
       "      <td>0.285407</td>\n",
       "      <td>0.301778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.087735</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>0.104332</td>\n",
       "      <td>0.377702</td>\n",
       "      <td>0.334039</td>\n",
       "      <td>0.341866</td>\n",
       "      <td>0.333112</td>\n",
       "      <td>0.075540</td>\n",
       "      <td>0.355332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03244189</th>\n",
       "      <td>0.318389</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.239077</td>\n",
       "      <td>0.223002</td>\n",
       "      <td>0.285023</td>\n",
       "      <td>0.264701</td>\n",
       "      <td>0.079138</td>\n",
       "      <td>0.345102</td>\n",
       "      <td>0.346678</td>\n",
       "      <td>0.288474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.102858</td>\n",
       "      <td>0.248124</td>\n",
       "      <td>0.151180</td>\n",
       "      <td>0.295379</td>\n",
       "      <td>0.364659</td>\n",
       "      <td>0.369742</td>\n",
       "      <td>0.369642</td>\n",
       "      <td>0.106677</td>\n",
       "      <td>0.292839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg03695421</th>\n",
       "      <td>0.431295</td>\n",
       "      <td>0.707087</td>\n",
       "      <td>0.413813</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573828</td>\n",
       "      <td>0.435571</td>\n",
       "      <td>0.314586</td>\n",
       "      <td>0.372958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373995</td>\n",
       "      <td>0.757837</td>\n",
       "      <td>0.400924</td>\n",
       "      <td>0.761376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.386185</td>\n",
       "      <td>0.363767</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.733518</td>\n",
       "      <td>0.411337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg04689676</th>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.068059</td>\n",
       "      <td>0.188884</td>\n",
       "      <td>0.200552</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>0.218308</td>\n",
       "      <td>0.055082</td>\n",
       "      <td>0.301970</td>\n",
       "      <td>0.290017</td>\n",
       "      <td>0.348960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234856</td>\n",
       "      <td>0.081985</td>\n",
       "      <td>0.264703</td>\n",
       "      <td>0.049703</td>\n",
       "      <td>0.195470</td>\n",
       "      <td>0.342306</td>\n",
       "      <td>0.276520</td>\n",
       "      <td>0.297719</td>\n",
       "      <td>0.077993</td>\n",
       "      <td>0.252178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg27553637</th>\n",
       "      <td>0.100750</td>\n",
       "      <td>0.092585</td>\n",
       "      <td>0.085468</td>\n",
       "      <td>0.085335</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>0.080868</td>\n",
       "      <td>0.147395</td>\n",
       "      <td>0.105346</td>\n",
       "      <td>0.084725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076533</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>0.076649</td>\n",
       "      <td>0.081364</td>\n",
       "      <td>0.099946</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>0.081617</td>\n",
       "      <td>0.123232</td>\n",
       "      <td>0.086865</td>\n",
       "      <td>0.090997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg27575890</th>\n",
       "      <td>0.433371</td>\n",
       "      <td>0.380250</td>\n",
       "      <td>0.374776</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>0.377906</td>\n",
       "      <td>0.337933</td>\n",
       "      <td>0.408589</td>\n",
       "      <td>0.427982</td>\n",
       "      <td>0.419254</td>\n",
       "      <td>0.376659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406881</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>0.334248</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.385733</td>\n",
       "      <td>0.395870</td>\n",
       "      <td>0.397042</td>\n",
       "      <td>0.408952</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>0.417783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg27585287</th>\n",
       "      <td>0.035770</td>\n",
       "      <td>0.043603</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.044939</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.041655</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.047275</td>\n",
       "      <td>0.062313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>0.052548</td>\n",
       "      <td>0.068112</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>0.048230</td>\n",
       "      <td>0.048466</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.054833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg27592453</th>\n",
       "      <td>0.829706</td>\n",
       "      <td>0.826126</td>\n",
       "      <td>0.843467</td>\n",
       "      <td>0.798517</td>\n",
       "      <td>0.801194</td>\n",
       "      <td>0.823062</td>\n",
       "      <td>0.834816</td>\n",
       "      <td>0.830896</td>\n",
       "      <td>0.839264</td>\n",
       "      <td>0.835588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840031</td>\n",
       "      <td>0.874013</td>\n",
       "      <td>0.844692</td>\n",
       "      <td>0.820715</td>\n",
       "      <td>0.807588</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.854933</td>\n",
       "      <td>0.855472</td>\n",
       "      <td>0.853569</td>\n",
       "      <td>0.787941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg27598806</th>\n",
       "      <td>0.890113</td>\n",
       "      <td>0.879804</td>\n",
       "      <td>0.893957</td>\n",
       "      <td>0.894712</td>\n",
       "      <td>0.876720</td>\n",
       "      <td>0.878338</td>\n",
       "      <td>0.866980</td>\n",
       "      <td>0.831732</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>0.865115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895555</td>\n",
       "      <td>0.907831</td>\n",
       "      <td>0.894163</td>\n",
       "      <td>0.824551</td>\n",
       "      <td>0.869527</td>\n",
       "      <td>0.883756</td>\n",
       "      <td>0.847659</td>\n",
       "      <td>0.828986</td>\n",
       "      <td>0.827940</td>\n",
       "      <td>0.876512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443206 rows Ã— 1425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                3630     10226     22854      5641     13515     26098  \\\n",
       "probe.id                                                                 \n",
       "cg00455876  0.340616  0.656693  0.279148  0.363048  0.373903  0.341001   \n",
       "cg01707559  0.341025  0.128761  0.393184  0.331995  0.352611  0.371087   \n",
       "cg03244189  0.318389  0.107887  0.239077  0.223002  0.285023  0.264701   \n",
       "cg03695421  0.431295  0.707087  0.413813  0.387546  0.343865       NaN   \n",
       "cg04689676  0.195909  0.068059  0.188884  0.200552  0.209481  0.218308   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "cg27553637  0.100750  0.092585  0.085468  0.085335  0.103806  0.071816   \n",
       "cg27575890  0.433371  0.380250  0.374776  0.381071  0.377906  0.337933   \n",
       "cg27585287  0.035770  0.043603  0.043326  0.044939  0.046019  0.038746   \n",
       "cg27592453  0.829706  0.826126  0.843467  0.798517  0.801194  0.823062   \n",
       "cg27598806  0.890113  0.879804  0.893957  0.894712  0.876720  0.878338   \n",
       "\n",
       "                4354      4892      8567       393  ...      9791     24702  \\\n",
       "probe.id                                            ...                       \n",
       "cg00455876  0.586655  0.472144  0.354304  0.406437  ...  0.318181  0.574336   \n",
       "cg01707559  0.094050  0.317272  0.285407  0.301778  ...  0.399217  0.087735   \n",
       "cg03244189  0.079138  0.345102  0.346678  0.288474  ...  0.266094  0.102858   \n",
       "cg03695421  0.573828  0.435571  0.314586  0.372958  ...  0.373995  0.757837   \n",
       "cg04689676  0.055082  0.301970  0.290017  0.348960  ...  0.234856  0.081985   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "cg27553637  0.080868  0.147395  0.105346  0.084725  ...  0.076533  0.086947   \n",
       "cg27575890  0.408589  0.427982  0.419254  0.376659  ...  0.406881  0.333335   \n",
       "cg27585287  0.041655  0.055870  0.047275  0.062313  ...  0.028468  0.045368   \n",
       "cg27592453  0.834816  0.830896  0.839264  0.835588  ...  0.840031  0.874013   \n",
       "cg27598806  0.866980  0.831732  0.849382  0.865115  ...  0.895555  0.907831   \n",
       "\n",
       "                5833      1692     11354      5197     18255      2077  \\\n",
       "probe.id                                                                 \n",
       "cg00455876  0.402250  0.542247  0.358957  0.407751  0.272390  0.430805   \n",
       "cg01707559  0.296028  0.104332  0.377702  0.334039  0.341866  0.333112   \n",
       "cg03244189  0.248124  0.151180  0.295379  0.364659  0.369742  0.369642   \n",
       "cg03695421  0.400924  0.761376       NaN  0.386185  0.363767  0.432547   \n",
       "cg04689676  0.264703  0.049703  0.195470  0.342306  0.276520  0.297719   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "cg27553637  0.076649  0.081364  0.099946  0.077326  0.081617  0.123232   \n",
       "cg27575890  0.334248  0.480800  0.385733  0.395870  0.397042  0.408952   \n",
       "cg27585287  0.052548  0.068112  0.042444  0.043853  0.048230  0.048466   \n",
       "cg27592453  0.844692  0.820715  0.807588  0.864127  0.854933  0.855472   \n",
       "cg27598806  0.894163  0.824551  0.869527  0.883756  0.847659  0.828986   \n",
       "\n",
       "               19268      1891  \n",
       "probe.id                        \n",
       "cg00455876  0.655632  0.391442  \n",
       "cg01707559  0.075540  0.355332  \n",
       "cg03244189  0.106677  0.292839  \n",
       "cg03695421  0.733518  0.411337  \n",
       "cg04689676  0.077993  0.252178  \n",
       "...              ...       ...  \n",
       "cg27553637  0.086865  0.090997  \n",
       "cg27575890  0.354646  0.417783  \n",
       "cg27585287  0.040517  0.054833  \n",
       "cg27592453  0.853569  0.787941  \n",
       "cg27598806  0.827940  0.876512  \n",
       "\n",
       "[443206 rows x 1425 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T # to have samples as rows and CpG sites as columns\n",
    "df.index.name = 'sample_id'\n",
    "# Adjust the index and remove 'probe.id' column\n",
    "# df = df.rename(columns={'probe.id': 'sample_id'}).set_index('sample_id')\n",
    "df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00455876</th>\n",
       "      <th>cg01707559</th>\n",
       "      <th>cg03244189</th>\n",
       "      <th>cg03695421</th>\n",
       "      <th>cg04689676</th>\n",
       "      <th>cg04792227</th>\n",
       "      <th>cg04964672</th>\n",
       "      <th>cg13851368</th>\n",
       "      <th>cg14180491</th>\n",
       "      <th>cg14210405</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27532867</th>\n",
       "      <th>cg27534599</th>\n",
       "      <th>cg27536559</th>\n",
       "      <th>cg27545494</th>\n",
       "      <th>cg27552198</th>\n",
       "      <th>cg27553637</th>\n",
       "      <th>cg27575890</th>\n",
       "      <th>cg27585287</th>\n",
       "      <th>cg27592453</th>\n",
       "      <th>cg27598806</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>0.340616</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.318389</td>\n",
       "      <td>0.431295</td>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.320329</td>\n",
       "      <td>0.700558</td>\n",
       "      <td>0.372461</td>\n",
       "      <td>0.519657</td>\n",
       "      <td>0.389533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052985</td>\n",
       "      <td>0.802725</td>\n",
       "      <td>0.178046</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>0.840077</td>\n",
       "      <td>0.100750</td>\n",
       "      <td>0.433371</td>\n",
       "      <td>0.035770</td>\n",
       "      <td>0.829706</td>\n",
       "      <td>0.890113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10226</th>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.128761</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.707087</td>\n",
       "      <td>0.068059</td>\n",
       "      <td>0.194810</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.828850</td>\n",
       "      <td>0.093967</td>\n",
       "      <td>0.400479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052807</td>\n",
       "      <td>0.793719</td>\n",
       "      <td>0.180809</td>\n",
       "      <td>0.037093</td>\n",
       "      <td>0.859426</td>\n",
       "      <td>0.092585</td>\n",
       "      <td>0.380250</td>\n",
       "      <td>0.043603</td>\n",
       "      <td>0.826126</td>\n",
       "      <td>0.879804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22854</th>\n",
       "      <td>0.279148</td>\n",
       "      <td>0.393184</td>\n",
       "      <td>0.239077</td>\n",
       "      <td>0.413813</td>\n",
       "      <td>0.188884</td>\n",
       "      <td>0.331690</td>\n",
       "      <td>0.580790</td>\n",
       "      <td>0.383639</td>\n",
       "      <td>0.525260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043946</td>\n",
       "      <td>0.781412</td>\n",
       "      <td>0.180760</td>\n",
       "      <td>0.046037</td>\n",
       "      <td>0.876665</td>\n",
       "      <td>0.085468</td>\n",
       "      <td>0.374776</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.843467</td>\n",
       "      <td>0.893957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>0.363048</td>\n",
       "      <td>0.331995</td>\n",
       "      <td>0.223002</td>\n",
       "      <td>0.387546</td>\n",
       "      <td>0.200552</td>\n",
       "      <td>0.352450</td>\n",
       "      <td>0.627094</td>\n",
       "      <td>0.340513</td>\n",
       "      <td>0.545357</td>\n",
       "      <td>0.349725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061374</td>\n",
       "      <td>0.763620</td>\n",
       "      <td>0.140669</td>\n",
       "      <td>0.047586</td>\n",
       "      <td>0.862237</td>\n",
       "      <td>0.085335</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>0.044939</td>\n",
       "      <td>0.798517</td>\n",
       "      <td>0.894712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.352611</td>\n",
       "      <td>0.285023</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>0.317307</td>\n",
       "      <td>0.654633</td>\n",
       "      <td>0.354590</td>\n",
       "      <td>0.478328</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.777402</td>\n",
       "      <td>0.140125</td>\n",
       "      <td>0.049228</td>\n",
       "      <td>0.854127</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.377906</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.801194</td>\n",
       "      <td>0.876720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 443206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00455876  cg01707559  cg03244189  cg03695421  cg04689676  \\\n",
       "sample_id                                                               \n",
       "3630         0.340616    0.341025    0.318389    0.431295    0.195909   \n",
       "10226        0.656693    0.128761    0.107887    0.707087    0.068059   \n",
       "22854        0.279148    0.393184    0.239077    0.413813    0.188884   \n",
       "5641         0.363048    0.331995    0.223002    0.387546    0.200552   \n",
       "13515        0.373903    0.352611    0.285023    0.343865    0.209481   \n",
       "\n",
       "           cg04792227  cg04964672  cg13851368  cg14180491  cg14210405  ...  \\\n",
       "sample_id                                                              ...   \n",
       "3630         0.320329    0.700558    0.372461    0.519657    0.389533  ...   \n",
       "10226        0.194810    0.908372    0.828850    0.093967    0.400479  ...   \n",
       "22854        0.331690    0.580790    0.383639    0.525260         NaN  ...   \n",
       "5641         0.352450    0.627094    0.340513    0.545357    0.349725  ...   \n",
       "13515        0.317307    0.654633    0.354590    0.478328    0.361801  ...   \n",
       "\n",
       "           cg27532867  cg27534599  cg27536559  cg27545494  cg27552198  \\\n",
       "sample_id                                                               \n",
       "3630         0.052985    0.802725    0.178046    0.045268    0.840077   \n",
       "10226        0.052807    0.793719    0.180809    0.037093    0.859426   \n",
       "22854        0.043946    0.781412    0.180760    0.046037    0.876665   \n",
       "5641         0.061374    0.763620    0.140669    0.047586    0.862237   \n",
       "13515        0.059121    0.777402    0.140125    0.049228    0.854127   \n",
       "\n",
       "           cg27553637  cg27575890  cg27585287  cg27592453  cg27598806  \n",
       "sample_id                                                              \n",
       "3630         0.100750    0.433371    0.035770    0.829706    0.890113  \n",
       "10226        0.092585    0.380250    0.043603    0.826126    0.879804  \n",
       "22854        0.085468    0.374776    0.043326    0.843467    0.893957  \n",
       "5641         0.085335    0.381071    0.044939    0.798517    0.894712  \n",
       "13515        0.103806    0.377906    0.046019    0.801194    0.876720  \n",
       "\n",
       "[5 rows x 443206 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert subject_id to string since sample_id is string type\n",
    "# metadata_df['subject_id'] = metadata_df['subject_id'].astype(str)\n",
    "\n",
    "# # Find common elements\n",
    "# common_ids = set(df.index).intersection(set(metadata_df['subject_id']))\n",
    "# print(f\"Number of common IDs: {len(common_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both identifiers to same type (string) for comparison\n",
    "metadata_df['subject_id'] = metadata_df['subject_id'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['3630', '10226', '22854', '5641', '13515', '26098', '4354', '4892',\n",
       "       '8567', '393',\n",
       "       ...\n",
       "       '9791', '24702', '5833', '1692', '11354', '5197', '18255', '2077',\n",
       "       '19268', '1891'],\n",
       "      dtype='object', name='sample_id', length=1425)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       11465\n",
       "1       17510\n",
       "2        3253\n",
       "3        5657\n",
       "4        9868\n",
       "        ...  \n",
       "1939    22904\n",
       "1940    24905\n",
       "1941    10703\n",
       "1942    21202\n",
       "1943     7114\n",
       "Name: subject_id, Length: 1944, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common IDs: 474\n"
     ]
    }
   ],
   "source": [
    "# Get common IDs\n",
    "common_ids = set(df.index.astype(str)).intersection(\n",
    "    set(metadata_df['subject_id'].astype(str))\n",
    ")\n",
    "print(f\"Number of common IDs: {len(common_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10001',\n",
       " '10006',\n",
       " '10008',\n",
       " '10022',\n",
       " '10026',\n",
       " '10057',\n",
       " '10073',\n",
       " '10077',\n",
       " '10082',\n",
       " '10121',\n",
       " '10274',\n",
       " '10358',\n",
       " '1037',\n",
       " '10391',\n",
       " '10393',\n",
       " '10439',\n",
       " '10496',\n",
       " '10534',\n",
       " '10699',\n",
       " '107',\n",
       " '10709',\n",
       " '10729',\n",
       " '10734',\n",
       " '10793',\n",
       " '10794',\n",
       " '10817',\n",
       " '10819',\n",
       " '1083',\n",
       " '10943',\n",
       " '11016',\n",
       " '11147',\n",
       " '11179',\n",
       " '11285',\n",
       " '11316',\n",
       " '11354',\n",
       " '11436',\n",
       " '11656',\n",
       " '117',\n",
       " '1170',\n",
       " '11800',\n",
       " '11853',\n",
       " '11945',\n",
       " '12076',\n",
       " '1210',\n",
       " '12264',\n",
       " '12276',\n",
       " '12436',\n",
       " '1246',\n",
       " '12535',\n",
       " '1265',\n",
       " '12707',\n",
       " '12814',\n",
       " '12848',\n",
       " '12912',\n",
       " '12989',\n",
       " '13004',\n",
       " '13025',\n",
       " '1308',\n",
       " '13094',\n",
       " '13192',\n",
       " '13227',\n",
       " '13272',\n",
       " '13299',\n",
       " '13425',\n",
       " '13454',\n",
       " '1348',\n",
       " '13515',\n",
       " '13519',\n",
       " '13618',\n",
       " '13647',\n",
       " '13780',\n",
       " '13794',\n",
       " '13823',\n",
       " '1387',\n",
       " '13998',\n",
       " '1423',\n",
       " '14251',\n",
       " '14303',\n",
       " '14341',\n",
       " '14405',\n",
       " '14417',\n",
       " '14419',\n",
       " '14467',\n",
       " '14533',\n",
       " '14554',\n",
       " '14594',\n",
       " '14614',\n",
       " '14640',\n",
       " '14674',\n",
       " '14676',\n",
       " '14678',\n",
       " '14767',\n",
       " '14829',\n",
       " '15050',\n",
       " '15085',\n",
       " '15120',\n",
       " '15184',\n",
       " '15437',\n",
       " '15458',\n",
       " '15543',\n",
       " '15570',\n",
       " '15690',\n",
       " '15738',\n",
       " '1574',\n",
       " '15791',\n",
       " '15802',\n",
       " '15978',\n",
       " '16022',\n",
       " '1611',\n",
       " '16139',\n",
       " '16160',\n",
       " '16167',\n",
       " '16288',\n",
       " '16322',\n",
       " '1636',\n",
       " '16401',\n",
       " '16414',\n",
       " '16419',\n",
       " '16420',\n",
       " '16476',\n",
       " '16478',\n",
       " '1659',\n",
       " '16632',\n",
       " '16706',\n",
       " '1678',\n",
       " '16785',\n",
       " '16815',\n",
       " '16835',\n",
       " '16859',\n",
       " '16870',\n",
       " '16897',\n",
       " '16928',\n",
       " '17015',\n",
       " '17025',\n",
       " '17055',\n",
       " '17090',\n",
       " '17110',\n",
       " '17174',\n",
       " '1721',\n",
       " '17223',\n",
       " '1725',\n",
       " '17334',\n",
       " '17378',\n",
       " '17381',\n",
       " '17468',\n",
       " '17472',\n",
       " '17498',\n",
       " '17523',\n",
       " '17582',\n",
       " '17587',\n",
       " '17654',\n",
       " '17726',\n",
       " '1773',\n",
       " '17790',\n",
       " '17801',\n",
       " '17803',\n",
       " '17823',\n",
       " '17839',\n",
       " '17881',\n",
       " '17899',\n",
       " '18003',\n",
       " '18063',\n",
       " '18064',\n",
       " '18079',\n",
       " '18228',\n",
       " '18282',\n",
       " '18308',\n",
       " '18321',\n",
       " '18324',\n",
       " '1835',\n",
       " '18378',\n",
       " '18529',\n",
       " '18632',\n",
       " '18717',\n",
       " '18730',\n",
       " '18746',\n",
       " '18879',\n",
       " '18896',\n",
       " '18957',\n",
       " '1900',\n",
       " '19044',\n",
       " '19060',\n",
       " '19107',\n",
       " '19138',\n",
       " '19176',\n",
       " '19228',\n",
       " '19244',\n",
       " '19268',\n",
       " '19567',\n",
       " '19610',\n",
       " '19746',\n",
       " '1977',\n",
       " '19861',\n",
       " '19863',\n",
       " '19903',\n",
       " '19913',\n",
       " '20099',\n",
       " '20104',\n",
       " '20129',\n",
       " '20192',\n",
       " '20195',\n",
       " '20211',\n",
       " '20217',\n",
       " '20255',\n",
       " '20277',\n",
       " '20294',\n",
       " '20309',\n",
       " '20340',\n",
       " '20469',\n",
       " '20505',\n",
       " '2062',\n",
       " '20664',\n",
       " '20687',\n",
       " '20706',\n",
       " '20739',\n",
       " '20752',\n",
       " '20796',\n",
       " '20891',\n",
       " '21034',\n",
       " '21068',\n",
       " '21088',\n",
       " '21110',\n",
       " '21129',\n",
       " '21172',\n",
       " '21234',\n",
       " '21275',\n",
       " '21280',\n",
       " '21314',\n",
       " '21505',\n",
       " '2154',\n",
       " '21638',\n",
       " '21660',\n",
       " '21697',\n",
       " '21811',\n",
       " '21960',\n",
       " '22075',\n",
       " '22077',\n",
       " '22106',\n",
       " '2229',\n",
       " '22304',\n",
       " '22377',\n",
       " '22407',\n",
       " '22418',\n",
       " '22434',\n",
       " '22467',\n",
       " '22468',\n",
       " '22584',\n",
       " '22593',\n",
       " '22729',\n",
       " '22771',\n",
       " '22825',\n",
       " '22931',\n",
       " '22969',\n",
       " '2309',\n",
       " '23216',\n",
       " '23341',\n",
       " '23363',\n",
       " '23388',\n",
       " '2342',\n",
       " '23428',\n",
       " '23495',\n",
       " '235',\n",
       " '23543',\n",
       " '23548',\n",
       " '23562',\n",
       " '23606',\n",
       " '23653',\n",
       " '23655',\n",
       " '23704',\n",
       " '23707',\n",
       " '23709',\n",
       " '23710',\n",
       " '23745',\n",
       " '23790',\n",
       " '23846',\n",
       " '2394',\n",
       " '24146',\n",
       " '24151',\n",
       " '24203',\n",
       " '24296',\n",
       " '2430',\n",
       " '24305',\n",
       " '24306',\n",
       " '24326',\n",
       " '24327',\n",
       " '24446',\n",
       " '24496',\n",
       " '24545',\n",
       " '24559',\n",
       " '24629',\n",
       " '24654',\n",
       " '24667',\n",
       " '24702',\n",
       " '24743',\n",
       " '2482',\n",
       " '24882',\n",
       " '24899',\n",
       " '24941',\n",
       " '2497',\n",
       " '24991',\n",
       " '24993',\n",
       " '24995',\n",
       " '2500',\n",
       " '25031',\n",
       " '2510',\n",
       " '25101',\n",
       " '25148',\n",
       " '25254',\n",
       " '25288',\n",
       " '25320',\n",
       " '25371',\n",
       " '25405',\n",
       " '25454',\n",
       " '25682',\n",
       " '25858',\n",
       " '25926',\n",
       " '25928',\n",
       " '25953',\n",
       " '26014',\n",
       " '26149',\n",
       " '26152',\n",
       " '26154',\n",
       " '26194',\n",
       " '26202',\n",
       " '26290',\n",
       " '26439',\n",
       " '26519',\n",
       " '26691',\n",
       " '26704',\n",
       " '26718',\n",
       " '26743',\n",
       " '2703',\n",
       " '2856',\n",
       " '2867',\n",
       " '2977',\n",
       " '3033',\n",
       " '3083',\n",
       " '3134',\n",
       " '3135',\n",
       " '3145',\n",
       " '3158',\n",
       " '317',\n",
       " '3197',\n",
       " '3291',\n",
       " '3390',\n",
       " '3511',\n",
       " '3583',\n",
       " '3711',\n",
       " '373',\n",
       " '3848',\n",
       " '3855',\n",
       " '3879',\n",
       " '3925',\n",
       " '3957',\n",
       " '4004',\n",
       " '4048',\n",
       " '4125',\n",
       " '422',\n",
       " '4249',\n",
       " '4359',\n",
       " '4360',\n",
       " '4407',\n",
       " '455',\n",
       " '4560',\n",
       " '4585',\n",
       " '4595',\n",
       " '4610',\n",
       " '4619',\n",
       " '4630',\n",
       " '4703',\n",
       " '4766',\n",
       " '4881',\n",
       " '4892',\n",
       " '4941',\n",
       " '4959',\n",
       " '5048',\n",
       " '5197',\n",
       " '5218',\n",
       " '5276',\n",
       " '5360',\n",
       " '5413',\n",
       " '5473',\n",
       " '5494',\n",
       " '5566',\n",
       " '5583',\n",
       " '5603',\n",
       " '565',\n",
       " '5884',\n",
       " '5910',\n",
       " '5949',\n",
       " '6016',\n",
       " '6058',\n",
       " '6068',\n",
       " '6173',\n",
       " '6179',\n",
       " '6200',\n",
       " '6256',\n",
       " '6310',\n",
       " '6358',\n",
       " '6364',\n",
       " '6395',\n",
       " '6471',\n",
       " '6576',\n",
       " '6590',\n",
       " '6662',\n",
       " '6670',\n",
       " '6736',\n",
       " '6746',\n",
       " '6765',\n",
       " '6821',\n",
       " '6899',\n",
       " '6952',\n",
       " '7089',\n",
       " '7092',\n",
       " '7120',\n",
       " '7132',\n",
       " '7206',\n",
       " '7312',\n",
       " '7376',\n",
       " '7383',\n",
       " '7420',\n",
       " '7543',\n",
       " '7560',\n",
       " '7565',\n",
       " '7581',\n",
       " '7658',\n",
       " '7717',\n",
       " '7743',\n",
       " '7764',\n",
       " '7786',\n",
       " '7881',\n",
       " '7929',\n",
       " '7933',\n",
       " '7982',\n",
       " '8020',\n",
       " '8028',\n",
       " '8052',\n",
       " '8147',\n",
       " '8155',\n",
       " '8215',\n",
       " '8250',\n",
       " '8257',\n",
       " '8276',\n",
       " '8294',\n",
       " '8461',\n",
       " '8633',\n",
       " '8639',\n",
       " '8658',\n",
       " '8808',\n",
       " '8856',\n",
       " '8938',\n",
       " '8964',\n",
       " '9003',\n",
       " '9043',\n",
       " '9045',\n",
       " '909',\n",
       " '9093',\n",
       " '9103',\n",
       " '9228',\n",
       " '9332',\n",
       " '9346',\n",
       " '9370',\n",
       " '9387',\n",
       " '9395',\n",
       " '9560',\n",
       " '9610',\n",
       " '971',\n",
       " '9743',\n",
       " '9771',\n",
       " '980',\n",
       " '9905',\n",
       " '9970',\n",
       " '9982',\n",
       " '9983'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of filtered methylation data: (474, 443206)\n",
      "Shape of filtered metadata: (478, 20)\n"
     ]
    }
   ],
   "source": [
    "# Filter both dataframes to keep only common IDs\n",
    "filtered_df = df[df.index.astype(str).isin(common_ids)]\n",
    "filtered_metadata = metadata_df[metadata_df['subject_id'].astype(str).isin(common_ids)]\n",
    "\n",
    "# Reset index for metadata_df to maintain consistency\n",
    "filtered_metadata = filtered_metadata.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nShape of filtered methylation data:\", filtered_df.shape)\n",
    "print(\"Shape of filtered metadata:\", filtered_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00455876</th>\n",
       "      <th>cg01707559</th>\n",
       "      <th>cg03244189</th>\n",
       "      <th>cg03695421</th>\n",
       "      <th>cg04689676</th>\n",
       "      <th>cg04792227</th>\n",
       "      <th>cg04964672</th>\n",
       "      <th>cg13851368</th>\n",
       "      <th>cg14180491</th>\n",
       "      <th>cg14210405</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27532867</th>\n",
       "      <th>cg27534599</th>\n",
       "      <th>cg27536559</th>\n",
       "      <th>cg27545494</th>\n",
       "      <th>cg27552198</th>\n",
       "      <th>cg27553637</th>\n",
       "      <th>cg27575890</th>\n",
       "      <th>cg27585287</th>\n",
       "      <th>cg27592453</th>\n",
       "      <th>cg27598806</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.352611</td>\n",
       "      <td>0.285023</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>0.317307</td>\n",
       "      <td>0.654633</td>\n",
       "      <td>0.354590</td>\n",
       "      <td>0.478328</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.777402</td>\n",
       "      <td>0.140125</td>\n",
       "      <td>0.049228</td>\n",
       "      <td>0.854127</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.377906</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.801194</td>\n",
       "      <td>0.876720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.317272</td>\n",
       "      <td>0.345102</td>\n",
       "      <td>0.435571</td>\n",
       "      <td>0.301970</td>\n",
       "      <td>0.346044</td>\n",
       "      <td>0.686608</td>\n",
       "      <td>0.455047</td>\n",
       "      <td>0.517205</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>0.758235</td>\n",
       "      <td>0.141635</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>0.838716</td>\n",
       "      <td>0.147395</td>\n",
       "      <td>0.427982</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.830896</td>\n",
       "      <td>0.831732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24654</th>\n",
       "      <td>0.364213</td>\n",
       "      <td>0.373167</td>\n",
       "      <td>0.383677</td>\n",
       "      <td>0.371633</td>\n",
       "      <td>0.400758</td>\n",
       "      <td>0.417855</td>\n",
       "      <td>0.709025</td>\n",
       "      <td>0.408174</td>\n",
       "      <td>0.521777</td>\n",
       "      <td>0.438885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>0.765001</td>\n",
       "      <td>0.236049</td>\n",
       "      <td>0.049031</td>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.097279</td>\n",
       "      <td>0.441205</td>\n",
       "      <td>0.053650</td>\n",
       "      <td>0.817943</td>\n",
       "      <td>0.848297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>0.645996</td>\n",
       "      <td>0.118774</td>\n",
       "      <td>0.109488</td>\n",
       "      <td>0.650313</td>\n",
       "      <td>0.073410</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>0.907011</td>\n",
       "      <td>0.842083</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>0.517147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053871</td>\n",
       "      <td>0.727399</td>\n",
       "      <td>0.181261</td>\n",
       "      <td>0.041696</td>\n",
       "      <td>0.846080</td>\n",
       "      <td>0.077593</td>\n",
       "      <td>0.353020</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.868281</td>\n",
       "      <td>0.872010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>0.393172</td>\n",
       "      <td>0.351914</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.432429</td>\n",
       "      <td>0.389742</td>\n",
       "      <td>0.377637</td>\n",
       "      <td>0.760646</td>\n",
       "      <td>0.465659</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.486697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.791954</td>\n",
       "      <td>0.221617</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.421793</td>\n",
       "      <td>0.055254</td>\n",
       "      <td>0.915611</td>\n",
       "      <td>0.863411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.097955</td>\n",
       "      <td>0.099898</td>\n",
       "      <td>0.712607</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.914319</td>\n",
       "      <td>0.820917</td>\n",
       "      <td>0.084572</td>\n",
       "      <td>0.525990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056571</td>\n",
       "      <td>0.800210</td>\n",
       "      <td>0.183646</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.862467</td>\n",
       "      <td>0.079173</td>\n",
       "      <td>0.367596</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.825740</td>\n",
       "      <td>0.884708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24702</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.087735</td>\n",
       "      <td>0.102858</td>\n",
       "      <td>0.757837</td>\n",
       "      <td>0.081985</td>\n",
       "      <td>0.140933</td>\n",
       "      <td>0.939900</td>\n",
       "      <td>0.802047</td>\n",
       "      <td>0.075081</td>\n",
       "      <td>0.469135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045415</td>\n",
       "      <td>0.786400</td>\n",
       "      <td>0.170066</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.881907</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>0.874013</td>\n",
       "      <td>0.907831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>0.358957</td>\n",
       "      <td>0.377702</td>\n",
       "      <td>0.295379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195470</td>\n",
       "      <td>0.293281</td>\n",
       "      <td>0.684217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.775111</td>\n",
       "      <td>0.186350</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.837358</td>\n",
       "      <td>0.099946</td>\n",
       "      <td>0.385733</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>0.807588</td>\n",
       "      <td>0.869527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>0.407751</td>\n",
       "      <td>0.334039</td>\n",
       "      <td>0.364659</td>\n",
       "      <td>0.386185</td>\n",
       "      <td>0.342306</td>\n",
       "      <td>0.415866</td>\n",
       "      <td>0.753173</td>\n",
       "      <td>0.414093</td>\n",
       "      <td>0.482597</td>\n",
       "      <td>0.372852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044422</td>\n",
       "      <td>0.770602</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.038365</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>0.395870</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.883756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19268</th>\n",
       "      <td>0.655632</td>\n",
       "      <td>0.075540</td>\n",
       "      <td>0.106677</td>\n",
       "      <td>0.733518</td>\n",
       "      <td>0.077993</td>\n",
       "      <td>0.147640</td>\n",
       "      <td>0.914338</td>\n",
       "      <td>0.823746</td>\n",
       "      <td>0.087397</td>\n",
       "      <td>0.465290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>0.781196</td>\n",
       "      <td>0.167518</td>\n",
       "      <td>0.042034</td>\n",
       "      <td>0.845079</td>\n",
       "      <td>0.086865</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.853569</td>\n",
       "      <td>0.827940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows Ã— 443206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00455876  cg01707559  cg03244189  cg03695421  cg04689676  \\\n",
       "sample_id                                                               \n",
       "13515        0.373903    0.352611    0.285023    0.343865    0.209481   \n",
       "4892         0.472144    0.317272    0.345102    0.435571    0.301970   \n",
       "24654        0.364213    0.373167    0.383677    0.371633    0.400758   \n",
       "8276         0.645996    0.118774    0.109488    0.650313    0.073410   \n",
       "23495        0.393172    0.351914    0.389313    0.432429    0.389742   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "7786         0.607018    0.097955    0.099898    0.712607    0.087751   \n",
       "24702        0.574336    0.087735    0.102858    0.757837    0.081985   \n",
       "11354        0.358957    0.377702    0.295379         NaN    0.195470   \n",
       "5197         0.407751    0.334039    0.364659    0.386185    0.342306   \n",
       "19268        0.655632    0.075540    0.106677    0.733518    0.077993   \n",
       "\n",
       "           cg04792227  cg04964672  cg13851368  cg14180491  cg14210405  ...  \\\n",
       "sample_id                                                              ...   \n",
       "13515        0.317307    0.654633    0.354590    0.478328    0.361801  ...   \n",
       "4892         0.346044    0.686608    0.455047    0.517205    0.399917  ...   \n",
       "24654        0.417855    0.709025    0.408174    0.521777    0.438885  ...   \n",
       "8276         0.202634    0.907011    0.842083    0.103456    0.517147  ...   \n",
       "23495        0.377637    0.760646    0.465659    0.482143    0.486697  ...   \n",
       "...               ...         ...         ...         ...         ...  ...   \n",
       "7786         0.176667    0.914319    0.820917    0.084572    0.525990  ...   \n",
       "24702        0.140933    0.939900    0.802047    0.075081    0.469135  ...   \n",
       "11354        0.293281    0.684217         NaN    0.553361         NaN  ...   \n",
       "5197         0.415866    0.753173    0.414093    0.482597    0.372852  ...   \n",
       "19268        0.147640    0.914338    0.823746    0.087397    0.465290  ...   \n",
       "\n",
       "           cg27532867  cg27534599  cg27536559  cg27545494  cg27552198  \\\n",
       "sample_id                                                               \n",
       "13515        0.059121    0.777402    0.140125    0.049228    0.854127   \n",
       "4892         0.061810    0.758235    0.141635    0.057578    0.838716   \n",
       "24654        0.064607    0.765001    0.236049    0.049031    0.848972   \n",
       "8276         0.053871    0.727399    0.181261    0.041696    0.846080   \n",
       "23495        0.055474    0.791954    0.221617    0.032351    0.859742   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "7786         0.056571    0.800210    0.183646    0.046256    0.862467   \n",
       "24702        0.045415    0.786400    0.170066    0.038829    0.881907   \n",
       "11354        0.063208    0.775111    0.186350    0.055446    0.837358   \n",
       "5197         0.044422    0.770602    0.199192    0.038365    0.851601   \n",
       "19268        0.053155    0.781196    0.167518    0.042034    0.845079   \n",
       "\n",
       "           cg27553637  cg27575890  cg27585287  cg27592453  cg27598806  \n",
       "sample_id                                                              \n",
       "13515        0.103806    0.377906    0.046019    0.801194    0.876720  \n",
       "4892         0.147395    0.427982    0.055870    0.830896    0.831732  \n",
       "24654        0.097279    0.441205    0.053650    0.817943    0.848297  \n",
       "8276         0.077593    0.353020    0.047327    0.868281    0.872010  \n",
       "23495        0.078798    0.421793    0.055254    0.915611    0.863411  \n",
       "...               ...         ...         ...         ...         ...  \n",
       "7786         0.079173    0.367596    0.049488    0.825740    0.884708  \n",
       "24702        0.086947    0.333335    0.045368    0.874013    0.907831  \n",
       "11354        0.099946    0.385733    0.042444    0.807588    0.869527  \n",
       "5197         0.077326    0.395870    0.043853    0.864127    0.883756  \n",
       "19268        0.086865    0.354646    0.040517    0.853569    0.827940  \n",
       "\n",
       "[474 rows x 443206 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>AgeAtBloodDraw</th>\n",
       "      <th>sex</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>haschip</th>\n",
       "      <th>Gene</th>\n",
       "      <th>ExonicFunc</th>\n",
       "      <th>VAF</th>\n",
       "      <th>chip_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWD290865</td>\n",
       "      <td>5360</td>\n",
       "      <td>36.709857</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1</td>\n",
       "      <td>NF1</td>\n",
       "      <td>stopgain</td>\n",
       "      <td>0.204</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWD757156</td>\n",
       "      <td>10022</td>\n",
       "      <td>59.817792</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>-0.001230</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.002286</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>-0.002682</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>nonsynonymous SNV</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWD925538</td>\n",
       "      <td>26014</td>\n",
       "      <td>60.461200</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>nonsynonymous SNV</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWD100436</td>\n",
       "      <td>7420</td>\n",
       "      <td>37.320410</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWD102395</td>\n",
       "      <td>5048</td>\n",
       "      <td>54.355668</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>-0.005667</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>-0.008498</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>NWD983190</td>\n",
       "      <td>2482</td>\n",
       "      <td>52.132487</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>NWD985467</td>\n",
       "      <td>9387</td>\n",
       "      <td>52.800537</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.001703</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>NWD985989</td>\n",
       "      <td>16928</td>\n",
       "      <td>53.476800</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>-0.009627</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>NWD986461</td>\n",
       "      <td>7658</td>\n",
       "      <td>51.341232</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>NWD989601</td>\n",
       "      <td>2510</td>\n",
       "      <td>53.380973</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sample  subject_id  AgeAtBloodDraw sex       PC1       PC2       PC3  \\\n",
       "0    NWD290865        5360       36.709857   M  0.002307 -0.001598 -0.000748   \n",
       "1    NWD757156       10022       59.817792   F  0.002145 -0.000661 -0.001230   \n",
       "2    NWD925538       26014       60.461200   F  0.002308 -0.001293 -0.000612   \n",
       "3    NWD100436        7420       37.320410   F  0.002331 -0.001710 -0.000732   \n",
       "4    NWD102395        5048       54.355668   F  0.002153 -0.001422 -0.000712   \n",
       "..         ...         ...             ...  ..       ...       ...       ...   \n",
       "473  NWD983190        2482       52.132487   M  0.002320 -0.001663 -0.000785   \n",
       "474  NWD985467        9387       52.800537   F  0.002239 -0.001547 -0.000839   \n",
       "475  NWD985989       16928       53.476800   F  0.002172 -0.001444 -0.000717   \n",
       "476  NWD986461        7658       51.341232   M  0.002356 -0.001783 -0.000793   \n",
       "477  NWD989601        2510       53.380973   F  0.002154 -0.001577 -0.000736   \n",
       "\n",
       "          PC4       PC5       PC6       PC7       PC8       PC9      PC10  \\\n",
       "0    0.000724  0.001564  0.000178 -0.000338  0.000049  0.000842  0.000176   \n",
       "1   -0.000578 -0.002286  0.000284  0.000642  0.002438  0.001718 -0.002682   \n",
       "2    0.000759  0.001243 -0.001005  0.000830  0.000047 -0.004544 -0.001970   \n",
       "3    0.001101  0.001999  0.000338 -0.000963 -0.000289  0.002154  0.002027   \n",
       "4   -0.002858 -0.005667  0.000936 -0.000473  0.003260  0.004069 -0.008498   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "473  0.000941  0.001791  0.000223 -0.000184 -0.000754  0.002305  0.002894   \n",
       "474 -0.000648 -0.001384 -0.001557  0.000079 -0.001703  0.001573  0.002124   \n",
       "475 -0.002625 -0.005104  0.000367 -0.000662  0.002821  0.002219 -0.009627   \n",
       "476  0.000784  0.001350  0.000012 -0.000920 -0.000942  0.002105  0.001099   \n",
       "477 -0.001524 -0.003078  0.002890 -0.002094  0.000489  0.003769 -0.005593   \n",
       "\n",
       "         PC11  haschip    Gene         ExonicFunc    VAF  chip_binary  \n",
       "0    0.000036        1     NF1           stopgain  0.204          1.0  \n",
       "1    0.001535        1  DNMT3A  nonsynonymous SNV  0.118          1.0  \n",
       "2    0.001056        1  DNMT3A  nonsynonymous SNV  0.289          1.0  \n",
       "3   -0.000200        0     NaN                NaN    NaN          NaN  \n",
       "4    0.004219        0     NaN                NaN    NaN          NaN  \n",
       "..        ...      ...     ...                ...    ...          ...  \n",
       "473  0.000044        0     NaN                NaN    NaN          NaN  \n",
       "474 -0.002207        0     NaN                NaN    NaN          NaN  \n",
       "475  0.003023        0     NaN                NaN    NaN          NaN  \n",
       "476 -0.000106        0     NaN                NaN    NaN          NaN  \n",
       "477  0.002401        0     NaN                NaN    NaN          NaN  \n",
       "\n",
       "[478 rows x 20 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_metadata['subject_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_subject_ids = metadata_df[metadata_df['subject_id'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>AgeAtBloodDraw</th>\n",
       "      <th>sex</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>haschip</th>\n",
       "      <th>Gene</th>\n",
       "      <th>ExonicFunc</th>\n",
       "      <th>VAF</th>\n",
       "      <th>chip_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>NWD143123</td>\n",
       "      <td>15960</td>\n",
       "      <td>58.128504</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NWD145350</td>\n",
       "      <td>18324</td>\n",
       "      <td>37.279342</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NWD167155</td>\n",
       "      <td>18324</td>\n",
       "      <td>37.279342</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>-0.000684</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>NWD284313</td>\n",
       "      <td>15960</td>\n",
       "      <td>58.128504</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>NWD321439</td>\n",
       "      <td>13823</td>\n",
       "      <td>32.008871</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>-0.001627</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>NWD433184</td>\n",
       "      <td>13823</td>\n",
       "      <td>32.008871</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>NWD465832</td>\n",
       "      <td>13823</td>\n",
       "      <td>32.008871</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>NWD481739</td>\n",
       "      <td>13823</td>\n",
       "      <td>32.008871</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>NWD507659</td>\n",
       "      <td>15960</td>\n",
       "      <td>58.128504</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>NWD641266</td>\n",
       "      <td>20156</td>\n",
       "      <td>56.912873</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>NWD805151</td>\n",
       "      <td>20472</td>\n",
       "      <td>60.622737</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>NWD808124</td>\n",
       "      <td>20156</td>\n",
       "      <td>56.912873</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>NWD813793</td>\n",
       "      <td>15960</td>\n",
       "      <td>58.128504</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>NWD820361</td>\n",
       "      <td>20156</td>\n",
       "      <td>56.912873</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>NWD978810</td>\n",
       "      <td>20472</td>\n",
       "      <td>60.622737</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>NWD985536</td>\n",
       "      <td>20156</td>\n",
       "      <td>56.912873</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>-0.001611</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sample  subject_id  AgeAtBloodDraw sex       PC1       PC2       PC3  \\\n",
       "204   NWD143123       15960       58.128504   M       NaN       NaN       NaN   \n",
       "210   NWD145350       18324       37.279342   F       NaN       NaN       NaN   \n",
       "249   NWD167155       18324       37.279342   F  0.002343 -0.001701 -0.000684   \n",
       "489   NWD284313       15960       58.128504   M       NaN       NaN       NaN   \n",
       "566   NWD321439       13823       32.008871   F  0.002324 -0.001627 -0.000700   \n",
       "783   NWD433184       13823       32.008871   F       NaN       NaN       NaN   \n",
       "837   NWD465832       13823       32.008871   F       NaN       NaN       NaN   \n",
       "873   NWD481739       13823       32.008871   F       NaN       NaN       NaN   \n",
       "926   NWD507659       15960       58.128504   M       NaN       NaN       NaN   \n",
       "1212  NWD641266       20156       56.912873   F       NaN       NaN       NaN   \n",
       "1539  NWD805151       20472       60.622737   M       NaN       NaN       NaN   \n",
       "1542  NWD808124       20156       56.912873   F       NaN       NaN       NaN   \n",
       "1557  NWD813793       15960       58.128504   M  0.002278 -0.001595 -0.000719   \n",
       "1570  NWD820361       20156       56.912873   F       NaN       NaN       NaN   \n",
       "1899  NWD978810       20472       60.622737   M  0.002342 -0.001729 -0.000679   \n",
       "1916  NWD985536       20156       56.912873   F  0.002351 -0.001611 -0.000768   \n",
       "\n",
       "           PC4       PC5       PC6       PC7       PC8       PC9      PC10  \\\n",
       "204        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "210        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "249   0.001081  0.002007  0.000348 -0.000267 -0.000026  0.002223  0.002199   \n",
       "489        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "566   0.000817  0.001509  0.000217 -0.000138 -0.000703  0.002087  0.002442   \n",
       "783        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "837        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "873        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "926        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1212       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1539       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1542       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1557  0.000083  0.000138  0.000382 -0.000569  0.000855  0.003199  0.000606   \n",
       "1570       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1899  0.000876  0.001677  0.000127 -0.000535 -0.000680  0.002512  0.001964   \n",
       "1916  0.001551  0.002791 -0.000544  0.000385 -0.001284  0.000632  0.003762   \n",
       "\n",
       "          PC11  haschip Gene ExonicFunc  VAF  chip_binary  \n",
       "204        NaN        0  NaN        NaN  NaN          NaN  \n",
       "210        NaN        0  NaN        NaN  NaN          NaN  \n",
       "249   0.000453        0  NaN        NaN  NaN          NaN  \n",
       "489        NaN        0  NaN        NaN  NaN          NaN  \n",
       "566   0.000910        0  NaN        NaN  NaN          NaN  \n",
       "783        NaN        0  NaN        NaN  NaN          NaN  \n",
       "837        NaN        0  NaN        NaN  NaN          NaN  \n",
       "873        NaN        0  NaN        NaN  NaN          NaN  \n",
       "926        NaN        0  NaN        NaN  NaN          NaN  \n",
       "1212       NaN        0  NaN        NaN  NaN          NaN  \n",
       "1539       NaN        0  NaN        NaN  NaN          NaN  \n",
       "1542       NaN        0  NaN        NaN  NaN          NaN  \n",
       "1557  0.001810        0  NaN        NaN  NaN          NaN  \n",
       "1570       NaN        0  NaN        NaN  NaN          NaN  \n",
       "1899  0.000414        0  NaN        NaN  NaN          NaN  \n",
       "1916 -0.000032        0  NaN        NaN  NaN          NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_subject_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the first occurrence of each subject_id\n",
    "filtered_metadata = filtered_metadata.drop_duplicates(subset='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>AgeAtBloodDraw</th>\n",
       "      <th>sex</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>haschip</th>\n",
       "      <th>Gene</th>\n",
       "      <th>ExonicFunc</th>\n",
       "      <th>VAF</th>\n",
       "      <th>chip_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWD290865</td>\n",
       "      <td>5360</td>\n",
       "      <td>36.709857</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1</td>\n",
       "      <td>NF1</td>\n",
       "      <td>stopgain</td>\n",
       "      <td>0.204</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWD757156</td>\n",
       "      <td>10022</td>\n",
       "      <td>59.817792</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>-0.001230</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.002286</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>-0.002682</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>nonsynonymous SNV</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWD925538</td>\n",
       "      <td>26014</td>\n",
       "      <td>60.461200</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>1</td>\n",
       "      <td>DNMT3A</td>\n",
       "      <td>nonsynonymous SNV</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWD100436</td>\n",
       "      <td>7420</td>\n",
       "      <td>37.320410</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWD102395</td>\n",
       "      <td>5048</td>\n",
       "      <td>54.355668</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>-0.005667</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>-0.008498</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>NWD983190</td>\n",
       "      <td>2482</td>\n",
       "      <td>52.132487</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>NWD985467</td>\n",
       "      <td>9387</td>\n",
       "      <td>52.800537</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.001703</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>NWD985989</td>\n",
       "      <td>16928</td>\n",
       "      <td>53.476800</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>-0.009627</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>NWD986461</td>\n",
       "      <td>7658</td>\n",
       "      <td>51.341232</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>NWD989601</td>\n",
       "      <td>2510</td>\n",
       "      <td>53.380973</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sample  subject_id  AgeAtBloodDraw sex       PC1       PC2       PC3  \\\n",
       "0    NWD290865        5360       36.709857   M  0.002307 -0.001598 -0.000748   \n",
       "1    NWD757156       10022       59.817792   F  0.002145 -0.000661 -0.001230   \n",
       "2    NWD925538       26014       60.461200   F  0.002308 -0.001293 -0.000612   \n",
       "3    NWD100436        7420       37.320410   F  0.002331 -0.001710 -0.000732   \n",
       "4    NWD102395        5048       54.355668   F  0.002153 -0.001422 -0.000712   \n",
       "..         ...         ...             ...  ..       ...       ...       ...   \n",
       "473  NWD983190        2482       52.132487   M  0.002320 -0.001663 -0.000785   \n",
       "474  NWD985467        9387       52.800537   F  0.002239 -0.001547 -0.000839   \n",
       "475  NWD985989       16928       53.476800   F  0.002172 -0.001444 -0.000717   \n",
       "476  NWD986461        7658       51.341232   M  0.002356 -0.001783 -0.000793   \n",
       "477  NWD989601        2510       53.380973   F  0.002154 -0.001577 -0.000736   \n",
       "\n",
       "          PC4       PC5       PC6       PC7       PC8       PC9      PC10  \\\n",
       "0    0.000724  0.001564  0.000178 -0.000338  0.000049  0.000842  0.000176   \n",
       "1   -0.000578 -0.002286  0.000284  0.000642  0.002438  0.001718 -0.002682   \n",
       "2    0.000759  0.001243 -0.001005  0.000830  0.000047 -0.004544 -0.001970   \n",
       "3    0.001101  0.001999  0.000338 -0.000963 -0.000289  0.002154  0.002027   \n",
       "4   -0.002858 -0.005667  0.000936 -0.000473  0.003260  0.004069 -0.008498   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "473  0.000941  0.001791  0.000223 -0.000184 -0.000754  0.002305  0.002894   \n",
       "474 -0.000648 -0.001384 -0.001557  0.000079 -0.001703  0.001573  0.002124   \n",
       "475 -0.002625 -0.005104  0.000367 -0.000662  0.002821  0.002219 -0.009627   \n",
       "476  0.000784  0.001350  0.000012 -0.000920 -0.000942  0.002105  0.001099   \n",
       "477 -0.001524 -0.003078  0.002890 -0.002094  0.000489  0.003769 -0.005593   \n",
       "\n",
       "         PC11  haschip    Gene         ExonicFunc    VAF  chip_binary  \n",
       "0    0.000036        1     NF1           stopgain  0.204          1.0  \n",
       "1    0.001535        1  DNMT3A  nonsynonymous SNV  0.118          1.0  \n",
       "2    0.001056        1  DNMT3A  nonsynonymous SNV  0.289          1.0  \n",
       "3   -0.000200        0     NaN                NaN    NaN          NaN  \n",
       "4    0.004219        0     NaN                NaN    NaN          NaN  \n",
       "..        ...      ...     ...                ...    ...          ...  \n",
       "473  0.000044        0     NaN                NaN    NaN          NaN  \n",
       "474 -0.002207        0     NaN                NaN    NaN          NaN  \n",
       "475  0.003023        0     NaN                NaN    NaN          NaN  \n",
       "476 -0.000106        0     NaN                NaN    NaN          NaN  \n",
       "477  0.002401        0     NaN                NaN    NaN          NaN  \n",
       "\n",
       "[474 rows x 20 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferencer.download_cpgcorpus_dataset(\"GSE182215\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to impute the methylation data for CpGPT -- it simply ignores the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(ARROW_DF_PATH)\n",
    "# df.set_index('GSM_ID', inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 443206)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Filter Vocab Features and Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not strictly required, filtering for the features used in finetuning gives you the best chance of achieving good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list\n",
    "vocab = json.load(open(MODEL_VOCAB_PATH, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ['cg00000292',\n",
       "  'cg00002426',\n",
       "  'cg00003994',\n",
       "  'cg00005847',\n",
       "  'cg00007981',\n",
       "  'cg00008493',\n",
       "  'cg00008713',\n",
       "  'cg00009407',\n",
       "  'cg00011459',\n",
       "  'cg00012199',\n",
       "  'cg00012386',\n",
       "  'cg00012792',\n",
       "  'cg00013618',\n",
       "  'cg00014085',\n",
       "  'cg00014837',\n",
       "  'cg00015770',\n",
       "  'cg00019495',\n",
       "  'cg00020533',\n",
       "  'cg00021527',\n",
       "  'cg00022866',\n",
       "  'cg00024396',\n",
       "  'cg00024812',\n",
       "  'cg00025991',\n",
       "  'cg00027083',\n",
       "  'cg00027674',\n",
       "  'cg00029826',\n",
       "  'cg00031162',\n",
       "  'cg00032227',\n",
       "  'cg00033516',\n",
       "  'cg00033773',\n",
       "  'cg00034039',\n",
       "  'cg00035347',\n",
       "  'cg00035623',\n",
       "  'cg00037763',\n",
       "  'cg00037940',\n",
       "  'cg00040861',\n",
       "  'cg00040873',\n",
       "  'cg00043004',\n",
       "  'cg00043080',\n",
       "  'cg00044245',\n",
       "  'cg00047050',\n",
       "  'cg00047469',\n",
       "  'cg00050312',\n",
       "  'cg00051979',\n",
       "  'cg00054706',\n",
       "  'cg00056767',\n",
       "  'cg00057593',\n",
       "  'cg00058938',\n",
       "  'cg00059424',\n",
       "  'cg00059930',\n",
       "  'cg00060762',\n",
       "  'cg00061059',\n",
       "  'cg00062776',\n",
       "  'cg00063144',\n",
       "  'cg00065385',\n",
       "  'cg00065408',\n",
       "  'cg00066816',\n",
       "  'cg00067471',\n",
       "  'cg00069261',\n",
       "  'cg00071250',\n",
       "  'cg00072216',\n",
       "  'cg00075967',\n",
       "  'cg00076645',\n",
       "  'cg00077877',\n",
       "  'cg00078194',\n",
       "  'cg00079056',\n",
       "  'cg00079563',\n",
       "  'cg00080012',\n",
       "  'cg00081935',\n",
       "  'cg00083937',\n",
       "  'cg00084687',\n",
       "  'cg00089071',\n",
       "  'cg00090147',\n",
       "  'cg00091693',\n",
       "  'cg00094851',\n",
       "  'cg00095526',\n",
       "  'cg00096922',\n",
       "  'cg00097536',\n",
       "  'cg00098162',\n",
       "  'cg00101227',\n",
       "  'cg00103783',\n",
       "  'cg00105253',\n",
       "  'cg00105470',\n",
       "  'cg00107187',\n",
       "  'cg00107488',\n",
       "  'cg00107632',\n",
       "  'cg00108454',\n",
       "  'cg00109274',\n",
       "  'cg00112517',\n",
       "  'cg00113020',\n",
       "  'cg00113951',\n",
       "  'cg00116234',\n",
       "  'cg00116838',\n",
       "  'cg00117172',\n",
       "  'cg00119079',\n",
       "  'cg00121158',\n",
       "  'cg00121640',\n",
       "  'cg00123035',\n",
       "  'cg00126034',\n",
       "  'cg00128560',\n",
       "  'cg00128654',\n",
       "  'cg00128877',\n",
       "  'cg00129774',\n",
       "  'cg00131557',\n",
       "  'cg00132141',\n",
       "  'cg00133909',\n",
       "  'cg00134787',\n",
       "  'cg00135056',\n",
       "  'cg00136105',\n",
       "  'cg00136477',\n",
       "  'cg00136736',\n",
       "  'cg00138126',\n",
       "  'cg00141162',\n",
       "  'cg00143376',\n",
       "  'cg00145118',\n",
       "  'cg00146096',\n",
       "  'cg00149659',\n",
       "  'cg00149976',\n",
       "  'cg00151607',\n",
       "  'cg00155167',\n",
       "  'cg00155485',\n",
       "  'cg00155609',\n",
       "  'cg00156216',\n",
       "  'cg00156744',\n",
       "  'cg00158308',\n",
       "  'cg00160914',\n",
       "  'cg00162401',\n",
       "  'cg00162643',\n",
       "  'cg00164898',\n",
       "  'cg00167504',\n",
       "  'cg00168082',\n",
       "  'cg00168785',\n",
       "  'cg00168942',\n",
       "  'cg00171126',\n",
       "  'cg00171161',\n",
       "  'cg00174500',\n",
       "  'cg00174901',\n",
       "  'cg00176210',\n",
       "  'cg00176879',\n",
       "  'cg00177013',\n",
       "  'cg00177698',\n",
       "  'cg00177923',\n",
       "  'cg00178790',\n",
       "  'cg00180012',\n",
       "  'cg00183916',\n",
       "  'cg00184893',\n",
       "  'cg00185103',\n",
       "  'cg00185839',\n",
       "  'cg00186701',\n",
       "  'cg00186954',\n",
       "  'cg00187380',\n",
       "  'cg00187686',\n",
       "  'cg00194146',\n",
       "  'cg00195561',\n",
       "  'cg00197641',\n",
       "  'cg00199549',\n",
       "  'cg00200063',\n",
       "  'cg00201234',\n",
       "  'cg00202702',\n",
       "  'cg00206052',\n",
       "  'cg00208830',\n",
       "  'cg00208967',\n",
       "  'cg00209066',\n",
       "  'cg00209951',\n",
       "  'cg00210842',\n",
       "  'cg00211661',\n",
       "  'cg00213331',\n",
       "  'cg00213714',\n",
       "  'cg00214855',\n",
       "  'cg00215066',\n",
       "  'cg00216361',\n",
       "  'cg00216758',\n",
       "  'cg00217795',\n",
       "  'cg00221494',\n",
       "  'cg00223186',\n",
       "  'cg00223950',\n",
       "  'cg00224508',\n",
       "  'cg00226904',\n",
       "  'cg00226923',\n",
       "  'cg00228799',\n",
       "  'cg00229387',\n",
       "  'cg00230271',\n",
       "  'cg00230368',\n",
       "  'cg00230502',\n",
       "  'cg00231644',\n",
       "  'cg00231920',\n",
       "  'cg00233307',\n",
       "  'cg00234616',\n",
       "  'cg00234961',\n",
       "  'cg00236832',\n",
       "  'cg00237010',\n",
       "  'cg00239071',\n",
       "  'cg00239685',\n",
       "  'cg00240432',\n",
       "  'cg00240880',\n",
       "  'cg00241355',\n",
       "  'cg00242839',\n",
       "  'cg00243313',\n",
       "  'cg00247489',\n",
       "  'cg00250430',\n",
       "  'cg00253200',\n",
       "  'cg00256074',\n",
       "  'cg00256166',\n",
       "  'cg00256281',\n",
       "  'cg00261552',\n",
       "  'cg00261781',\n",
       "  'cg00262415',\n",
       "  'cg00263760',\n",
       "  'cg00265415',\n",
       "  'cg00265490',\n",
       "  'cg00268009',\n",
       "  'cg00268338',\n",
       "  'cg00269115',\n",
       "  'cg00273068',\n",
       "  'cg00273124',\n",
       "  'cg00274399',\n",
       "  'cg00275232',\n",
       "  'cg00276797',\n",
       "  'cg00278366',\n",
       "  'cg00280814',\n",
       "  'cg00282347',\n",
       "  'cg00282683',\n",
       "  'cg00288562',\n",
       "  'cg00290028',\n",
       "  'cg00290506',\n",
       "  'cg00291877',\n",
       "  'cg00292662',\n",
       "  'cg00292971',\n",
       "  'cg00293409',\n",
       "  'cg00294382',\n",
       "  'cg00295206',\n",
       "  'cg00297584',\n",
       "  'cg00297600',\n",
       "  'cg00298357',\n",
       "  'cg00302793',\n",
       "  'cg00303548',\n",
       "  'cg00307685',\n",
       "  'cg00308133',\n",
       "  'cg00308665',\n",
       "  'cg00309056',\n",
       "  'cg00309204',\n",
       "  'cg00311768',\n",
       "  'cg00312919',\n",
       "  'cg00314943',\n",
       "  'cg00315936',\n",
       "  'cg00317680',\n",
       "  'cg00318573',\n",
       "  'cg00318865',\n",
       "  'cg00319692',\n",
       "  'cg00320243',\n",
       "  'cg00321478',\n",
       "  'cg00323915',\n",
       "  'cg00324733',\n",
       "  'cg00325491',\n",
       "  'cg00327185',\n",
       "  'cg00327483',\n",
       "  'cg00328227',\n",
       "  'cg00332153',\n",
       "  'cg00332745',\n",
       "  'cg00333226',\n",
       "  'cg00333528',\n",
       "  'cg00334507',\n",
       "  'cg00335286',\n",
       "  'cg00336605',\n",
       "  'cg00338702',\n",
       "  'cg00338893',\n",
       "  'cg00340102',\n",
       "  'cg00342530',\n",
       "  'cg00343092',\n",
       "  'cg00344358',\n",
       "  'cg00344372',\n",
       "  'cg00346145',\n",
       "  'cg00347729',\n",
       "  'cg00347904',\n",
       "  'cg00350296',\n",
       "  'cg00350478',\n",
       "  'cg00350702',\n",
       "  'cg00353953',\n",
       "  'cg00354572',\n",
       "  'cg00355802',\n",
       "  'cg00359325',\n",
       "  'cg00363813',\n",
       "  'cg00364814',\n",
       "  'cg00367438',\n",
       "  'cg00368415',\n",
       "  'cg00371195',\n",
       "  'cg00374717',\n",
       "  'cg00375964',\n",
       "  'cg00376639',\n",
       "  'cg00380464',\n",
       "  'cg00381076',\n",
       "  'cg00384537',\n",
       "  'cg00386408',\n",
       "  'cg00387170',\n",
       "  'cg00393585',\n",
       "  'cg00394658',\n",
       "  'cg00396163',\n",
       "  'cg00396894',\n",
       "  'cg00397740',\n",
       "  'cg00398048',\n",
       "  'cg00399483',\n",
       "  'cg00400263',\n",
       "  'cg00402366',\n",
       "  'cg00405070',\n",
       "  'cg00405568',\n",
       "  'cg00405677',\n",
       "  'cg00407150',\n",
       "  'cg00410419',\n",
       "  'cg00410576',\n",
       "  'cg00410895',\n",
       "  'cg00410898',\n",
       "  'cg00411097',\n",
       "  'cg00412772',\n",
       "  'cg00412805',\n",
       "  'cg00413066',\n",
       "  'cg00415993',\n",
       "  'cg00417297',\n",
       "  'cg00418150',\n",
       "  'cg00419564',\n",
       "  'cg00420568',\n",
       "  'cg00420715',\n",
       "  'cg00420929',\n",
       "  'cg00422913',\n",
       "  'cg00424946',\n",
       "  'cg00425710',\n",
       "  'cg00426056',\n",
       "  'cg00426498',\n",
       "  'cg00426963',\n",
       "  'cg00427635',\n",
       "  'cg00430287',\n",
       "  'cg00430945',\n",
       "  'cg00431050',\n",
       "  'cg00431549',\n",
       "  'cg00432979',\n",
       "  'cg00433406',\n",
       "  'cg00435408',\n",
       "  'cg00436282',\n",
       "  'cg00436301',\n",
       "  'cg00436603',\n",
       "  'cg00441382',\n",
       "  'cg00445824',\n",
       "  'cg00446235',\n",
       "  'cg00447208',\n",
       "  'cg00448720',\n",
       "  'cg00449941',\n",
       "  'cg00451635',\n",
       "  'cg00453193',\n",
       "  'cg00459975',\n",
       "  'cg00461841',\n",
       "  'cg00462994',\n",
       "  'cg00463202',\n",
       "  'cg00463577',\n",
       "  'cg00463848',\n",
       "  'cg00464269',\n",
       "  'cg00465284',\n",
       "  'cg00466249',\n",
       "  'cg00466492',\n",
       "  'cg00466544',\n",
       "  'cg00468146',\n",
       "  'cg00469635',\n",
       "  'cg00471562',\n",
       "  'cg00472814',\n",
       "  'cg00474004',\n",
       "  'cg00474209',\n",
       "  'cg00475955',\n",
       "  'cg00476580',\n",
       "  'cg00479269',\n",
       "  'cg00480115',\n",
       "  'cg00480356',\n",
       "  'cg00483154',\n",
       "  'cg00485296',\n",
       "  'cg00485380',\n",
       "  'cg00487159',\n",
       "  'cg00488718',\n",
       "  'cg00489401',\n",
       "  'cg00491404',\n",
       "  'cg00491839',\n",
       "  'cg00493400',\n",
       "  'cg00495415',\n",
       "  'cg00495442',\n",
       "  'cg00496170',\n",
       "  'cg00497251',\n",
       "  'cg00498305',\n",
       "  'cg00499599',\n",
       "  'cg00499822',\n",
       "  'cg00500400',\n",
       "  'cg00501366',\n",
       "  'cg00502442',\n",
       "  'cg00503458',\n",
       "  'cg00503840',\n",
       "  'cg00504595',\n",
       "  'cg00509616',\n",
       "  'cg00510787',\n",
       "  'cg00510956',\n",
       "  'cg00511475',\n",
       "  'cg00512031',\n",
       "  'cg00512279',\n",
       "  'cg00512374',\n",
       "  'cg00513467',\n",
       "  'cg00514407',\n",
       "  'cg00514895',\n",
       "  'cg00515905',\n",
       "  'cg00516481',\n",
       "  'cg00518989',\n",
       "  'cg00519627',\n",
       "  'cg00520135',\n",
       "  'cg00521434',\n",
       "  'cg00522034',\n",
       "  'cg00522316',\n",
       "  'cg00528052',\n",
       "  'cg00528967',\n",
       "  'cg00532335',\n",
       "  'cg00532890',\n",
       "  'cg00534274',\n",
       "  'cg00537910',\n",
       "  'cg00539322',\n",
       "  'cg00539716',\n",
       "  'cg00540544',\n",
       "  'cg00544557',\n",
       "  'cg00545573',\n",
       "  'cg00546491',\n",
       "  'cg00546897',\n",
       "  'cg00547018',\n",
       "  'cg00548060',\n",
       "  'cg00548268',\n",
       "  'cg00550617',\n",
       "  'cg00551244',\n",
       "  'cg00554173',\n",
       "  'cg00554250',\n",
       "  'cg00554682',\n",
       "  'cg00554702',\n",
       "  'cg00556408',\n",
       "  'cg00559473',\n",
       "  'cg00560119',\n",
       "  'cg00563229',\n",
       "  'cg00563926',\n",
       "  'cg00563932',\n",
       "  'cg00564163',\n",
       "  'cg00565075',\n",
       "  'cg00565688',\n",
       "  'cg00566759',\n",
       "  'cg00567479',\n",
       "  'cg00567749',\n",
       "  'cg00568128',\n",
       "  'cg00568792',\n",
       "  'cg00569620',\n",
       "  'cg00571634',\n",
       "  'cg00573606',\n",
       "  'cg00575744',\n",
       "  'cg00576250',\n",
       "  'cg00577167',\n",
       "  'cg00577464',\n",
       "  'cg00581156',\n",
       "  'cg00582628',\n",
       "  'cg00584022',\n",
       "  'cg00585790',\n",
       "  'cg00585846',\n",
       "  'cg00587613',\n",
       "  'cg00594118',\n",
       "  'cg00594952',\n",
       "  'cg00597076',\n",
       "  'cg00598858',\n",
       "  'cg00601486',\n",
       "  'cg00602891',\n",
       "  'cg00605270',\n",
       "  'cg00609097',\n",
       "  'cg00611397',\n",
       "  'cg00612467',\n",
       "  'cg00613255',\n",
       "  'cg00613344',\n",
       "  'cg00615241',\n",
       "  'cg00615377',\n",
       "  'cg00615915',\n",
       "  'cg00616129',\n",
       "  'cg00616135',\n",
       "  'cg00616369',\n",
       "  'cg00617305',\n",
       "  'cg00619207',\n",
       "  'cg00620024',\n",
       "  'cg00620629',\n",
       "  'cg00622552',\n",
       "  'cg00622677',\n",
       "  'cg00623593',\n",
       "  'cg00625425',\n",
       "  'cg00626119',\n",
       "  'cg00626466',\n",
       "  'cg00629217',\n",
       "  'cg00630164',\n",
       "  'cg00630249',\n",
       "  'cg00630583',\n",
       "  'cg00631230',\n",
       "  'cg00633969',\n",
       "  'cg00635481',\n",
       "  'cg00636639',\n",
       "  'cg00638514',\n",
       "  'cg00642303',\n",
       "  'cg00643392',\n",
       "  'cg00644033',\n",
       "  'cg00645579',\n",
       "  'cg00645922',\n",
       "  'cg00646492',\n",
       "  'cg00647741',\n",
       "  'cg00648153',\n",
       "  'cg00648883',\n",
       "  'cg00650762',\n",
       "  'cg00650876',\n",
       "  'cg00651216',\n",
       "  'cg00653387',\n",
       "  'cg00654814',\n",
       "  'cg00654816',\n",
       "  'cg00655307',\n",
       "  'cg00655779',\n",
       "  'cg00657095',\n",
       "  'cg00657582',\n",
       "  'cg00658007',\n",
       "  'cg00658626',\n",
       "  'cg00659129',\n",
       "  'cg00659953',\n",
       "  'cg00660989',\n",
       "  'cg00661202',\n",
       "  'cg00662556',\n",
       "  'cg00665395',\n",
       "  'cg00666446',\n",
       "  'cg00666746',\n",
       "  'cg00668685',\n",
       "  'cg00669856',\n",
       "  'cg00671161',\n",
       "  'cg00672638',\n",
       "  'cg00673191',\n",
       "  'cg00676660',\n",
       "  'cg00677811',\n",
       "  'cg00678539',\n",
       "  'cg00679556',\n",
       "  'cg00679738',\n",
       "  'cg00682653',\n",
       "  'cg00685836',\n",
       "  'cg00686022',\n",
       "  'cg00686623',\n",
       "  'cg00687674',\n",
       "  'cg00687686',\n",
       "  'cg00688421',\n",
       "  'cg00689010',\n",
       "  'cg00689340',\n",
       "  'cg00690280',\n",
       "  'cg00691625',\n",
       "  'cg00692549',\n",
       "  'cg00702231',\n",
       "  'cg00702729',\n",
       "  'cg00704310',\n",
       "  'cg00704909',\n",
       "  'cg00707317',\n",
       "  'cg00708598',\n",
       "  'cg00708642',\n",
       "  'cg00711916',\n",
       "  'cg00712898',\n",
       "  'cg00714377',\n",
       "  'cg00717862',\n",
       "  'cg00718440',\n",
       "  'cg00718513',\n",
       "  'cg00718748',\n",
       "  'cg00720072',\n",
       "  'cg00720137',\n",
       "  'cg00720723',\n",
       "  'cg00722300',\n",
       "  'cg00724662',\n",
       "  'cg00725635',\n",
       "  'cg00727590',\n",
       "  'cg00727947',\n",
       "  'cg00728317',\n",
       "  'cg00728398',\n",
       "  'cg00728602',\n",
       "  'cg00729275',\n",
       "  'cg00729541',\n",
       "  'cg00729875',\n",
       "  'cg00731459',\n",
       "  'cg00736326',\n",
       "  'cg00739120',\n",
       "  'cg00743372',\n",
       "  'cg00744433',\n",
       "  'cg00745543',\n",
       "  'cg00745735',\n",
       "  'cg00746083',\n",
       "  'cg00747849',\n",
       "  'cg00750606',\n",
       "  'cg00751288',\n",
       "  'cg00754253',\n",
       "  'cg00754617',\n",
       "  'cg00755043',\n",
       "  'cg00756887',\n",
       "  'cg00757070',\n",
       "  'cg00757952',\n",
       "  'cg00761755',\n",
       "  'cg00762512',\n",
       "  'cg00763679',\n",
       "  'cg00763889',\n",
       "  'cg00766729',\n",
       "  'cg00767581',\n",
       "  'cg00769470',\n",
       "  'cg00769520',\n",
       "  'cg00770279',\n",
       "  'cg00772000',\n",
       "  'cg00775197',\n",
       "  'cg00777121',\n",
       "  'cg00777555',\n",
       "  'cg00778920',\n",
       "  'cg00779924',\n",
       "  'cg00782174',\n",
       "  'cg00782854',\n",
       "  'cg00783759',\n",
       "  'cg00784357',\n",
       "  'cg00791249',\n",
       "  'cg00792687',\n",
       "  'cg00792740',\n",
       "  'cg00793648',\n",
       "  'cg00793774',\n",
       "  'cg00795268',\n",
       "  'cg00795812',\n",
       "  'cg00796728',\n",
       "  'cg00798206',\n",
       "  'cg00804048',\n",
       "  'cg00804392',\n",
       "  'cg00806490',\n",
       "  'cg00807586',\n",
       "  'cg00808492',\n",
       "  'cg00810473',\n",
       "  'cg00810495',\n",
       "  'cg00812502',\n",
       "  'cg00814580',\n",
       "  'cg00815440',\n",
       "  'cg00815583',\n",
       "  'cg00816620',\n",
       "  'cg00818693',\n",
       "  'cg00818872',\n",
       "  'cg00819310',\n",
       "  'cg00819362',\n",
       "  'cg00819696',\n",
       "  'cg00821764',\n",
       "  'cg00822607',\n",
       "  'cg00823148',\n",
       "  'cg00824109',\n",
       "  'cg00826384',\n",
       "  'cg00827369',\n",
       "  'cg00828602',\n",
       "  'cg00830029',\n",
       "  'cg00830393',\n",
       "  'cg00831028',\n",
       "  'cg00832517',\n",
       "  'cg00833393',\n",
       "  'cg00834958',\n",
       "  'cg00836605',\n",
       "  'cg00837103',\n",
       "  'cg00838150',\n",
       "  'cg00839584',\n",
       "  'cg00839802',\n",
       "  'cg00840403',\n",
       "  'cg00840516',\n",
       "  'cg00841581',\n",
       "  'cg00845900',\n",
       "  'cg00846036',\n",
       "  'cg00848394',\n",
       "  'cg00848397',\n",
       "  'cg00848728',\n",
       "  'cg00849368',\n",
       "  'cg00850538',\n",
       "  'cg00852964',\n",
       "  'cg00853068',\n",
       "  'cg00854637',\n",
       "  'cg00854995',\n",
       "  'cg00856375',\n",
       "  'cg00858899',\n",
       "  'cg00859193',\n",
       "  'cg00861635',\n",
       "  'cg00862290',\n",
       "  'cg00862770',\n",
       "  'cg00864867',\n",
       "  'cg00870662',\n",
       "  'cg00871453',\n",
       "  'cg00873037',\n",
       "  'cg00873937',\n",
       "  'cg00875272',\n",
       "  'cg00876704',\n",
       "  'cg00877887',\n",
       "  'cg00877964',\n",
       "  'cg00881086',\n",
       "  'cg00881370',\n",
       "  'cg00882451',\n",
       "  'cg00882832',\n",
       "  'cg00884221',\n",
       "  'cg00884529',\n",
       "  'cg00885506',\n",
       "  'cg00886554',\n",
       "  'cg00887101',\n",
       "  'cg00887547',\n",
       "  'cg00887700',\n",
       "  'cg00888007',\n",
       "  'cg00888479',\n",
       "  'cg00888561',\n",
       "  'cg00890257',\n",
       "  'cg00891278',\n",
       "  'cg00892798',\n",
       "  'cg00893242',\n",
       "  'cg00893636',\n",
       "  'cg00897329',\n",
       "  'cg00899086',\n",
       "  'cg00899641',\n",
       "  'cg00899659',\n",
       "  'cg00901493',\n",
       "  'cg00901652',\n",
       "  'cg00901683',\n",
       "  'cg00901704',\n",
       "  'cg00901766',\n",
       "  'cg00903242',\n",
       "  'cg00904483',\n",
       "  'cg00904574',\n",
       "  'cg00905170',\n",
       "  'cg00906183',\n",
       "  'cg00908551',\n",
       "  'cg00910067',\n",
       "  'cg00910168',\n",
       "  'cg00911873',\n",
       "  'cg00915289',\n",
       "  'cg00916199',\n",
       "  'cg00916635',\n",
       "  'cg00917893',\n",
       "  'cg00918794',\n",
       "  'cg00919857',\n",
       "  'cg00922727',\n",
       "  'cg00925229',\n",
       "  'cg00925717',\n",
       "  'cg00929606',\n",
       "  'cg00929855',\n",
       "  'cg00930078',\n",
       "  'cg00930194',\n",
       "  'cg00933411',\n",
       "  'cg00935388',\n",
       "  'cg00935430',\n",
       "  'cg00936626',\n",
       "  'cg00940278',\n",
       "  'cg00940891',\n",
       "  'cg00941229',\n",
       "  'cg00943245',\n",
       "  'cg00943909',\n",
       "  'cg00943950',\n",
       "  'cg00945507',\n",
       "  'cg00945862',\n",
       "  'cg00947019',\n",
       "  'cg00948524',\n",
       "  'cg00950418',\n",
       "  'cg00950621',\n",
       "  'cg00951770',\n",
       "  'cg00953256',\n",
       "  'cg00953277',\n",
       "  'cg00954003',\n",
       "  'cg00954566',\n",
       "  'cg00955230',\n",
       "  'cg00955451',\n",
       "  'cg00958517',\n",
       "  'cg00960702',\n",
       "  'cg00962459',\n",
       "  'cg00964109',\n",
       "  'cg00970325',\n",
       "  'cg00971396',\n",
       "  'cg00973286',\n",
       "  'cg00973334',\n",
       "  'cg00973677',\n",
       "  'cg00976054',\n",
       "  'cg00979348',\n",
       "  'cg00980978',\n",
       "  'cg00983520',\n",
       "  'cg00983899',\n",
       "  'cg00984602',\n",
       "  'cg00987015',\n",
       "  'cg00987379',\n",
       "  'cg00995065',\n",
       "  'cg00995152',\n",
       "  'cg00995327',\n",
       "  'cg00995520',\n",
       "  'cg01000094',\n",
       "  'cg01001286',\n",
       "  'cg01007201',\n",
       "  'cg01009664',\n",
       "  'cg01013324',\n",
       "  'cg01015871',\n",
       "  'cg01015879',\n",
       "  'cg01021485',\n",
       "  'cg01025842',\n",
       "  'cg01026744',\n",
       "  'cg01027739',\n",
       "  'cg01027805',\n",
       "  'cg01029592',\n",
       "  'cg01031251',\n",
       "  'cg01031400',\n",
       "  'cg01033160',\n",
       "  'cg01035238',\n",
       "  'cg01035422',\n",
       "  'cg01036148',\n",
       "  'cg01036173',\n",
       "  'cg01036779',\n",
       "  'cg01037108',\n",
       "  'cg01040062',\n",
       "  'cg01040759',\n",
       "  'cg01040850',\n",
       "  'cg01041367',\n",
       "  'cg01044662',\n",
       "  'cg01044722',\n",
       "  'cg01046174',\n",
       "  'cg01047414',\n",
       "  'cg01048931',\n",
       "  'cg01049530',\n",
       "  'cg01050433',\n",
       "  'cg01053621',\n",
       "  'cg01055695',\n",
       "  'cg01056568',\n",
       "  'cg01057962',\n",
       "  'cg01058368',\n",
       "  'cg01062029',\n",
       "  'cg01063524',\n",
       "  'cg01064307',\n",
       "  'cg01064957',\n",
       "  'cg01065920',\n",
       "  'cg01069256',\n",
       "  'cg01071811',\n",
       "  'cg01072821',\n",
       "  'cg01076838',\n",
       "  'cg01078276',\n",
       "  'cg01078434',\n",
       "  'cg01081263',\n",
       "  'cg01086895',\n",
       "  'cg01086978',\n",
       "  'cg01087382',\n",
       "  'cg01087710',\n",
       "  'cg01090445',\n",
       "  'cg01091448',\n",
       "  'cg01091565',\n",
       "  'cg01092036',\n",
       "  'cg01092561',\n",
       "  'cg01095590',\n",
       "  'cg01097940',\n",
       "  'cg01100784',\n",
       "  'cg01100796',\n",
       "  'cg01103730',\n",
       "  'cg01103836',\n",
       "  'cg01104423',\n",
       "  'cg01106788',\n",
       "  'cg01107031',\n",
       "  'cg01107741',\n",
       "  'cg01108476',\n",
       "  'cg01110312',\n",
       "  'cg01110846',\n",
       "  'cg01112778',\n",
       "  'cg01114088',\n",
       "  'cg01116966',\n",
       "  'cg01117627',\n",
       "  'cg01119135',\n",
       "  'cg01120165',\n",
       "  'cg01120307',\n",
       "  'cg01120308',\n",
       "  'cg01120898',\n",
       "  'cg01124420',\n",
       "  'cg01124961',\n",
       "  'cg01125463',\n",
       "  'cg01126560',\n",
       "  'cg01127428',\n",
       "  'cg01128603',\n",
       "  'cg01129459',\n",
       "  'cg01130192',\n",
       "  'cg01131735',\n",
       "  'cg01135200',\n",
       "  'cg01136458',\n",
       "  'cg01137065',\n",
       "  'cg01137198',\n",
       "  'cg01137532',\n",
       "  'cg01137708',\n",
       "  'cg01137737',\n",
       "  'cg01138020',\n",
       "  'cg01139059',\n",
       "  'cg01139966',\n",
       "  'cg01141769',\n",
       "  'cg01143454',\n",
       "  'cg01144286',\n",
       "  'cg01145389',\n",
       "  'cg01145396',\n",
       "  'cg01146980',\n",
       "  'cg01148741',\n",
       "  'cg01150454',\n",
       "  'cg01151686',\n",
       "  'cg01151699',\n",
       "  'cg01152019',\n",
       "  'cg01152499',\n",
       "  'cg01154193',\n",
       "  'cg01154537',\n",
       "  'cg01154775',\n",
       "  'cg01155039',\n",
       "  'cg01161216',\n",
       "  'cg01161597',\n",
       "  'cg01168201',\n",
       "  'cg01169610',\n",
       "  'cg01169624',\n",
       "  'cg01169726',\n",
       "  'cg01169778',\n",
       "  'cg01171588',\n",
       "  'cg01172656',\n",
       "  'cg01172735',\n",
       "  'cg01172899',\n",
       "  'cg01172972',\n",
       "  'cg01173186',\n",
       "  'cg01173291',\n",
       "  'cg01176271',\n",
       "  'cg01177524',\n",
       "  'cg01177956',\n",
       "  'cg01182585',\n",
       "  'cg01182697',\n",
       "  'cg01182873',\n",
       "  'cg01183669',\n",
       "  'cg01184449',\n",
       "  'cg01184522',\n",
       "  'cg01185080',\n",
       "  'cg01185754',\n",
       "  'cg01186777',\n",
       "  'cg01190915',\n",
       "  'cg01192900',\n",
       "  'cg01193293',\n",
       "  'cg01194444',\n",
       "  'cg01195053',\n",
       "  'cg01195127',\n",
       "  'cg01197831',\n",
       "  'cg01199721',\n",
       "  'cg01200060',\n",
       "  'cg01200177',\n",
       "  'cg01204271',\n",
       "  'cg01206472',\n",
       "  'cg01206970',\n",
       "  'cg01211097',\n",
       "  'cg01214321',\n",
       "  'cg01214847',\n",
       "  'cg01216369',\n",
       "  'cg01220033',\n",
       "  'cg01221484',\n",
       "  'cg01221637',\n",
       "  'cg01222684',\n",
       "  'cg01226811',\n",
       "  'cg01226883',\n",
       "  'cg01228636',\n",
       "  'cg01230160',\n",
       "  'cg01231779',\n",
       "  'cg01234063',\n",
       "  'cg01234133',\n",
       "  'cg01236137',\n",
       "  'cg01240931',\n",
       "  'cg01241375',\n",
       "  'cg01243790',\n",
       "  'cg01244871',\n",
       "  'cg01245595',\n",
       "  'cg01246405',\n",
       "  'cg01248426',\n",
       "  'cg01252496',\n",
       "  'cg01253107',\n",
       "  'cg01254459',\n",
       "  'cg01254505',\n",
       "  'cg01255349',\n",
       "  'cg01259619',\n",
       "  'cg01260219',\n",
       "  'cg01261503',\n",
       "  'cg01261535',\n",
       "  'cg01262913',\n",
       "  'cg01263716',\n",
       "  'cg01264826',\n",
       "  'cg01265637',\n",
       "  'cg01267315',\n",
       "  'cg01269048',\n",
       "  'cg01269795',\n",
       "  'cg01272601',\n",
       "  'cg01273150',\n",
       "  'cg01274324',\n",
       "  'cg01274660',\n",
       "  'cg01275830',\n",
       "  'cg01277844',\n",
       "  'cg01278291',\n",
       "  'cg01278696',\n",
       "  'cg01280080',\n",
       "  'cg01281904',\n",
       "  'cg01282074',\n",
       "  'cg01282432',\n",
       "  'cg01283289',\n",
       "  'cg01284306',\n",
       "  'cg01284619',\n",
       "  'cg01288067',\n",
       "  'cg01289103',\n",
       "  'cg01291404',\n",
       "  'cg01292265',\n",
       "  'cg01293143',\n",
       "  'cg01293647',\n",
       "  'cg01294695',\n",
       "  'cg01294702',\n",
       "  'cg01295203',\n",
       "  'cg01297972',\n",
       "  'cg01299496',\n",
       "  'cg01301664',\n",
       "  'cg01302245',\n",
       "  'cg01305421',\n",
       "  ...],\n",
       " 'output': ['cpgpt_age']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'output'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cg00000292',\n",
       " 'cg00002426',\n",
       " 'cg00003994',\n",
       " 'cg00005847',\n",
       " 'cg00007981',\n",
       " 'cg00008493',\n",
       " 'cg00008713',\n",
       " 'cg00009407',\n",
       " 'cg00011459',\n",
       " 'cg00012199',\n",
       " 'cg00012386',\n",
       " 'cg00012792',\n",
       " 'cg00013618',\n",
       " 'cg00014085',\n",
       " 'cg00014837',\n",
       " 'cg00015770',\n",
       " 'cg00019495',\n",
       " 'cg00020533',\n",
       " 'cg00021527',\n",
       " 'cg00022866',\n",
       " 'cg00024396',\n",
       " 'cg00024812',\n",
       " 'cg00025991',\n",
       " 'cg00027083',\n",
       " 'cg00027674',\n",
       " 'cg00029826',\n",
       " 'cg00031162',\n",
       " 'cg00032227',\n",
       " 'cg00033516',\n",
       " 'cg00033773',\n",
       " 'cg00034039',\n",
       " 'cg00035347',\n",
       " 'cg00035623',\n",
       " 'cg00037763',\n",
       " 'cg00037940',\n",
       " 'cg00040861',\n",
       " 'cg00040873',\n",
       " 'cg00043004',\n",
       " 'cg00043080',\n",
       " 'cg00044245',\n",
       " 'cg00047050',\n",
       " 'cg00047469',\n",
       " 'cg00050312',\n",
       " 'cg00051979',\n",
       " 'cg00054706',\n",
       " 'cg00056767',\n",
       " 'cg00057593',\n",
       " 'cg00058938',\n",
       " 'cg00059424',\n",
       " 'cg00059930',\n",
       " 'cg00060762',\n",
       " 'cg00061059',\n",
       " 'cg00062776',\n",
       " 'cg00063144',\n",
       " 'cg00065385',\n",
       " 'cg00065408',\n",
       " 'cg00066816',\n",
       " 'cg00067471',\n",
       " 'cg00069261',\n",
       " 'cg00071250',\n",
       " 'cg00072216',\n",
       " 'cg00075967',\n",
       " 'cg00076645',\n",
       " 'cg00077877',\n",
       " 'cg00078194',\n",
       " 'cg00079056',\n",
       " 'cg00079563',\n",
       " 'cg00080012',\n",
       " 'cg00081935',\n",
       " 'cg00083937',\n",
       " 'cg00084687',\n",
       " 'cg00089071',\n",
       " 'cg00090147',\n",
       " 'cg00091693',\n",
       " 'cg00094851',\n",
       " 'cg00095526',\n",
       " 'cg00096922',\n",
       " 'cg00097536',\n",
       " 'cg00098162',\n",
       " 'cg00101227',\n",
       " 'cg00103783',\n",
       " 'cg00105253',\n",
       " 'cg00105470',\n",
       " 'cg00107187',\n",
       " 'cg00107488',\n",
       " 'cg00107632',\n",
       " 'cg00108454',\n",
       " 'cg00109274',\n",
       " 'cg00112517',\n",
       " 'cg00113020',\n",
       " 'cg00113951',\n",
       " 'cg00116234',\n",
       " 'cg00116838',\n",
       " 'cg00117172',\n",
       " 'cg00119079',\n",
       " 'cg00121158',\n",
       " 'cg00121640',\n",
       " 'cg00123035',\n",
       " 'cg00126034',\n",
       " 'cg00128560',\n",
       " 'cg00128654',\n",
       " 'cg00128877',\n",
       " 'cg00129774',\n",
       " 'cg00131557',\n",
       " 'cg00132141',\n",
       " 'cg00133909',\n",
       " 'cg00134787',\n",
       " 'cg00135056',\n",
       " 'cg00136105',\n",
       " 'cg00136477',\n",
       " 'cg00136736',\n",
       " 'cg00138126',\n",
       " 'cg00141162',\n",
       " 'cg00143376',\n",
       " 'cg00145118',\n",
       " 'cg00146096',\n",
       " 'cg00149659',\n",
       " 'cg00149976',\n",
       " 'cg00151607',\n",
       " 'cg00155167',\n",
       " 'cg00155485',\n",
       " 'cg00155609',\n",
       " 'cg00156216',\n",
       " 'cg00156744',\n",
       " 'cg00158308',\n",
       " 'cg00160914',\n",
       " 'cg00162401',\n",
       " 'cg00162643',\n",
       " 'cg00164898',\n",
       " 'cg00167504',\n",
       " 'cg00168082',\n",
       " 'cg00168785',\n",
       " 'cg00168942',\n",
       " 'cg00171126',\n",
       " 'cg00171161',\n",
       " 'cg00174500',\n",
       " 'cg00174901',\n",
       " 'cg00176210',\n",
       " 'cg00176879',\n",
       " 'cg00177013',\n",
       " 'cg00177698',\n",
       " 'cg00177923',\n",
       " 'cg00178790',\n",
       " 'cg00180012',\n",
       " 'cg00183916',\n",
       " 'cg00184893',\n",
       " 'cg00185103',\n",
       " 'cg00185839',\n",
       " 'cg00186701',\n",
       " 'cg00186954',\n",
       " 'cg00187380',\n",
       " 'cg00187686',\n",
       " 'cg00194146',\n",
       " 'cg00195561',\n",
       " 'cg00197641',\n",
       " 'cg00199549',\n",
       " 'cg00200063',\n",
       " 'cg00201234',\n",
       " 'cg00202702',\n",
       " 'cg00206052',\n",
       " 'cg00208830',\n",
       " 'cg00208967',\n",
       " 'cg00209066',\n",
       " 'cg00209951',\n",
       " 'cg00210842',\n",
       " 'cg00211661',\n",
       " 'cg00213331',\n",
       " 'cg00213714',\n",
       " 'cg00214855',\n",
       " 'cg00215066',\n",
       " 'cg00216361',\n",
       " 'cg00216758',\n",
       " 'cg00217795',\n",
       " 'cg00221494',\n",
       " 'cg00223186',\n",
       " 'cg00223950',\n",
       " 'cg00224508',\n",
       " 'cg00226904',\n",
       " 'cg00226923',\n",
       " 'cg00228799',\n",
       " 'cg00229387',\n",
       " 'cg00230271',\n",
       " 'cg00230368',\n",
       " 'cg00230502',\n",
       " 'cg00231644',\n",
       " 'cg00231920',\n",
       " 'cg00233307',\n",
       " 'cg00234616',\n",
       " 'cg00234961',\n",
       " 'cg00236832',\n",
       " 'cg00237010',\n",
       " 'cg00239071',\n",
       " 'cg00239685',\n",
       " 'cg00240432',\n",
       " 'cg00240880',\n",
       " 'cg00241355',\n",
       " 'cg00242839',\n",
       " 'cg00243313',\n",
       " 'cg00247489',\n",
       " 'cg00250430',\n",
       " 'cg00253200',\n",
       " 'cg00256074',\n",
       " 'cg00256166',\n",
       " 'cg00256281',\n",
       " 'cg00261552',\n",
       " 'cg00261781',\n",
       " 'cg00262415',\n",
       " 'cg00263760',\n",
       " 'cg00265415',\n",
       " 'cg00265490',\n",
       " 'cg00268009',\n",
       " 'cg00268338',\n",
       " 'cg00269115',\n",
       " 'cg00273068',\n",
       " 'cg00273124',\n",
       " 'cg00274399',\n",
       " 'cg00275232',\n",
       " 'cg00276797',\n",
       " 'cg00278366',\n",
       " 'cg00280814',\n",
       " 'cg00282347',\n",
       " 'cg00282683',\n",
       " 'cg00288562',\n",
       " 'cg00290028',\n",
       " 'cg00290506',\n",
       " 'cg00291877',\n",
       " 'cg00292662',\n",
       " 'cg00292971',\n",
       " 'cg00293409',\n",
       " 'cg00294382',\n",
       " 'cg00295206',\n",
       " 'cg00297584',\n",
       " 'cg00297600',\n",
       " 'cg00298357',\n",
       " 'cg00302793',\n",
       " 'cg00303548',\n",
       " 'cg00307685',\n",
       " 'cg00308133',\n",
       " 'cg00308665',\n",
       " 'cg00309056',\n",
       " 'cg00309204',\n",
       " 'cg00311768',\n",
       " 'cg00312919',\n",
       " 'cg00314943',\n",
       " 'cg00315936',\n",
       " 'cg00317680',\n",
       " 'cg00318573',\n",
       " 'cg00318865',\n",
       " 'cg00319692',\n",
       " 'cg00320243',\n",
       " 'cg00321478',\n",
       " 'cg00323915',\n",
       " 'cg00324733',\n",
       " 'cg00325491',\n",
       " 'cg00327185',\n",
       " 'cg00327483',\n",
       " 'cg00328227',\n",
       " 'cg00332153',\n",
       " 'cg00332745',\n",
       " 'cg00333226',\n",
       " 'cg00333528',\n",
       " 'cg00334507',\n",
       " 'cg00335286',\n",
       " 'cg00336605',\n",
       " 'cg00338702',\n",
       " 'cg00338893',\n",
       " 'cg00340102',\n",
       " 'cg00342530',\n",
       " 'cg00343092',\n",
       " 'cg00344358',\n",
       " 'cg00344372',\n",
       " 'cg00346145',\n",
       " 'cg00347729',\n",
       " 'cg00347904',\n",
       " 'cg00350296',\n",
       " 'cg00350478',\n",
       " 'cg00350702',\n",
       " 'cg00353953',\n",
       " 'cg00354572',\n",
       " 'cg00355802',\n",
       " 'cg00359325',\n",
       " 'cg00363813',\n",
       " 'cg00364814',\n",
       " 'cg00367438',\n",
       " 'cg00368415',\n",
       " 'cg00371195',\n",
       " 'cg00374717',\n",
       " 'cg00375964',\n",
       " 'cg00376639',\n",
       " 'cg00380464',\n",
       " 'cg00381076',\n",
       " 'cg00384537',\n",
       " 'cg00386408',\n",
       " 'cg00387170',\n",
       " 'cg00393585',\n",
       " 'cg00394658',\n",
       " 'cg00396163',\n",
       " 'cg00396894',\n",
       " 'cg00397740',\n",
       " 'cg00398048',\n",
       " 'cg00399483',\n",
       " 'cg00400263',\n",
       " 'cg00402366',\n",
       " 'cg00405070',\n",
       " 'cg00405568',\n",
       " 'cg00405677',\n",
       " 'cg00407150',\n",
       " 'cg00410419',\n",
       " 'cg00410576',\n",
       " 'cg00410895',\n",
       " 'cg00410898',\n",
       " 'cg00411097',\n",
       " 'cg00412772',\n",
       " 'cg00412805',\n",
       " 'cg00413066',\n",
       " 'cg00415993',\n",
       " 'cg00417297',\n",
       " 'cg00418150',\n",
       " 'cg00419564',\n",
       " 'cg00420568',\n",
       " 'cg00420715',\n",
       " 'cg00420929',\n",
       " 'cg00422913',\n",
       " 'cg00424946',\n",
       " 'cg00425710',\n",
       " 'cg00426056',\n",
       " 'cg00426498',\n",
       " 'cg00426963',\n",
       " 'cg00427635',\n",
       " 'cg00430287',\n",
       " 'cg00430945',\n",
       " 'cg00431050',\n",
       " 'cg00431549',\n",
       " 'cg00432979',\n",
       " 'cg00433406',\n",
       " 'cg00435408',\n",
       " 'cg00436282',\n",
       " 'cg00436301',\n",
       " 'cg00436603',\n",
       " 'cg00441382',\n",
       " 'cg00445824',\n",
       " 'cg00446235',\n",
       " 'cg00447208',\n",
       " 'cg00448720',\n",
       " 'cg00449941',\n",
       " 'cg00451635',\n",
       " 'cg00453193',\n",
       " 'cg00459975',\n",
       " 'cg00461841',\n",
       " 'cg00462994',\n",
       " 'cg00463202',\n",
       " 'cg00463577',\n",
       " 'cg00463848',\n",
       " 'cg00464269',\n",
       " 'cg00465284',\n",
       " 'cg00466249',\n",
       " 'cg00466492',\n",
       " 'cg00466544',\n",
       " 'cg00468146',\n",
       " 'cg00469635',\n",
       " 'cg00471562',\n",
       " 'cg00472814',\n",
       " 'cg00474004',\n",
       " 'cg00474209',\n",
       " 'cg00475955',\n",
       " 'cg00476580',\n",
       " 'cg00479269',\n",
       " 'cg00480115',\n",
       " 'cg00480356',\n",
       " 'cg00483154',\n",
       " 'cg00485296',\n",
       " 'cg00485380',\n",
       " 'cg00487159',\n",
       " 'cg00488718',\n",
       " 'cg00489401',\n",
       " 'cg00491404',\n",
       " 'cg00491839',\n",
       " 'cg00493400',\n",
       " 'cg00495415',\n",
       " 'cg00495442',\n",
       " 'cg00496170',\n",
       " 'cg00497251',\n",
       " 'cg00498305',\n",
       " 'cg00499599',\n",
       " 'cg00499822',\n",
       " 'cg00500400',\n",
       " 'cg00501366',\n",
       " 'cg00502442',\n",
       " 'cg00503458',\n",
       " 'cg00503840',\n",
       " 'cg00504595',\n",
       " 'cg00509616',\n",
       " 'cg00510787',\n",
       " 'cg00510956',\n",
       " 'cg00511475',\n",
       " 'cg00512031',\n",
       " 'cg00512279',\n",
       " 'cg00512374',\n",
       " 'cg00513467',\n",
       " 'cg00514407',\n",
       " 'cg00514895',\n",
       " 'cg00515905',\n",
       " 'cg00516481',\n",
       " 'cg00518989',\n",
       " 'cg00519627',\n",
       " 'cg00520135',\n",
       " 'cg00521434',\n",
       " 'cg00522034',\n",
       " 'cg00522316',\n",
       " 'cg00528052',\n",
       " 'cg00528967',\n",
       " 'cg00532335',\n",
       " 'cg00532890',\n",
       " 'cg00534274',\n",
       " 'cg00537910',\n",
       " 'cg00539322',\n",
       " 'cg00539716',\n",
       " 'cg00540544',\n",
       " 'cg00544557',\n",
       " 'cg00545573',\n",
       " 'cg00546491',\n",
       " 'cg00546897',\n",
       " 'cg00547018',\n",
       " 'cg00548060',\n",
       " 'cg00548268',\n",
       " 'cg00550617',\n",
       " 'cg00551244',\n",
       " 'cg00554173',\n",
       " 'cg00554250',\n",
       " 'cg00554682',\n",
       " 'cg00554702',\n",
       " 'cg00556408',\n",
       " 'cg00559473',\n",
       " 'cg00560119',\n",
       " 'cg00563229',\n",
       " 'cg00563926',\n",
       " 'cg00563932',\n",
       " 'cg00564163',\n",
       " 'cg00565075',\n",
       " 'cg00565688',\n",
       " 'cg00566759',\n",
       " 'cg00567479',\n",
       " 'cg00567749',\n",
       " 'cg00568128',\n",
       " 'cg00568792',\n",
       " 'cg00569620',\n",
       " 'cg00571634',\n",
       " 'cg00573606',\n",
       " 'cg00575744',\n",
       " 'cg00576250',\n",
       " 'cg00577167',\n",
       " 'cg00577464',\n",
       " 'cg00581156',\n",
       " 'cg00582628',\n",
       " 'cg00584022',\n",
       " 'cg00585790',\n",
       " 'cg00585846',\n",
       " 'cg00587613',\n",
       " 'cg00594118',\n",
       " 'cg00594952',\n",
       " 'cg00597076',\n",
       " 'cg00598858',\n",
       " 'cg00601486',\n",
       " 'cg00602891',\n",
       " 'cg00605270',\n",
       " 'cg00609097',\n",
       " 'cg00611397',\n",
       " 'cg00612467',\n",
       " 'cg00613255',\n",
       " 'cg00613344',\n",
       " 'cg00615241',\n",
       " 'cg00615377',\n",
       " 'cg00615915',\n",
       " 'cg00616129',\n",
       " 'cg00616135',\n",
       " 'cg00616369',\n",
       " 'cg00617305',\n",
       " 'cg00619207',\n",
       " 'cg00620024',\n",
       " 'cg00620629',\n",
       " 'cg00622552',\n",
       " 'cg00622677',\n",
       " 'cg00623593',\n",
       " 'cg00625425',\n",
       " 'cg00626119',\n",
       " 'cg00626466',\n",
       " 'cg00629217',\n",
       " 'cg00630164',\n",
       " 'cg00630249',\n",
       " 'cg00630583',\n",
       " 'cg00631230',\n",
       " 'cg00633969',\n",
       " 'cg00635481',\n",
       " 'cg00636639',\n",
       " 'cg00638514',\n",
       " 'cg00642303',\n",
       " 'cg00643392',\n",
       " 'cg00644033',\n",
       " 'cg00645579',\n",
       " 'cg00645922',\n",
       " 'cg00646492',\n",
       " 'cg00647741',\n",
       " 'cg00648153',\n",
       " 'cg00648883',\n",
       " 'cg00650762',\n",
       " 'cg00650876',\n",
       " 'cg00651216',\n",
       " 'cg00653387',\n",
       " 'cg00654814',\n",
       " 'cg00654816',\n",
       " 'cg00655307',\n",
       " 'cg00655779',\n",
       " 'cg00657095',\n",
       " 'cg00657582',\n",
       " 'cg00658007',\n",
       " 'cg00658626',\n",
       " 'cg00659129',\n",
       " 'cg00659953',\n",
       " 'cg00660989',\n",
       " 'cg00661202',\n",
       " 'cg00662556',\n",
       " 'cg00665395',\n",
       " 'cg00666446',\n",
       " 'cg00666746',\n",
       " 'cg00668685',\n",
       " 'cg00669856',\n",
       " 'cg00671161',\n",
       " 'cg00672638',\n",
       " 'cg00673191',\n",
       " 'cg00676660',\n",
       " 'cg00677811',\n",
       " 'cg00678539',\n",
       " 'cg00679556',\n",
       " 'cg00679738',\n",
       " 'cg00682653',\n",
       " 'cg00685836',\n",
       " 'cg00686022',\n",
       " 'cg00686623',\n",
       " 'cg00687674',\n",
       " 'cg00687686',\n",
       " 'cg00688421',\n",
       " 'cg00689010',\n",
       " 'cg00689340',\n",
       " 'cg00690280',\n",
       " 'cg00691625',\n",
       " 'cg00692549',\n",
       " 'cg00702231',\n",
       " 'cg00702729',\n",
       " 'cg00704310',\n",
       " 'cg00704909',\n",
       " 'cg00707317',\n",
       " 'cg00708598',\n",
       " 'cg00708642',\n",
       " 'cg00711916',\n",
       " 'cg00712898',\n",
       " 'cg00714377',\n",
       " 'cg00717862',\n",
       " 'cg00718440',\n",
       " 'cg00718513',\n",
       " 'cg00718748',\n",
       " 'cg00720072',\n",
       " 'cg00720137',\n",
       " 'cg00720723',\n",
       " 'cg00722300',\n",
       " 'cg00724662',\n",
       " 'cg00725635',\n",
       " 'cg00727590',\n",
       " 'cg00727947',\n",
       " 'cg00728317',\n",
       " 'cg00728398',\n",
       " 'cg00728602',\n",
       " 'cg00729275',\n",
       " 'cg00729541',\n",
       " 'cg00729875',\n",
       " 'cg00731459',\n",
       " 'cg00736326',\n",
       " 'cg00739120',\n",
       " 'cg00743372',\n",
       " 'cg00744433',\n",
       " 'cg00745543',\n",
       " 'cg00745735',\n",
       " 'cg00746083',\n",
       " 'cg00747849',\n",
       " 'cg00750606',\n",
       " 'cg00751288',\n",
       " 'cg00754253',\n",
       " 'cg00754617',\n",
       " 'cg00755043',\n",
       " 'cg00756887',\n",
       " 'cg00757070',\n",
       " 'cg00757952',\n",
       " 'cg00761755',\n",
       " 'cg00762512',\n",
       " 'cg00763679',\n",
       " 'cg00763889',\n",
       " 'cg00766729',\n",
       " 'cg00767581',\n",
       " 'cg00769470',\n",
       " 'cg00769520',\n",
       " 'cg00770279',\n",
       " 'cg00772000',\n",
       " 'cg00775197',\n",
       " 'cg00777121',\n",
       " 'cg00777555',\n",
       " 'cg00778920',\n",
       " 'cg00779924',\n",
       " 'cg00782174',\n",
       " 'cg00782854',\n",
       " 'cg00783759',\n",
       " 'cg00784357',\n",
       " 'cg00791249',\n",
       " 'cg00792687',\n",
       " 'cg00792740',\n",
       " 'cg00793648',\n",
       " 'cg00793774',\n",
       " 'cg00795268',\n",
       " 'cg00795812',\n",
       " 'cg00796728',\n",
       " 'cg00798206',\n",
       " 'cg00804048',\n",
       " 'cg00804392',\n",
       " 'cg00806490',\n",
       " 'cg00807586',\n",
       " 'cg00808492',\n",
       " 'cg00810473',\n",
       " 'cg00810495',\n",
       " 'cg00812502',\n",
       " 'cg00814580',\n",
       " 'cg00815440',\n",
       " 'cg00815583',\n",
       " 'cg00816620',\n",
       " 'cg00818693',\n",
       " 'cg00818872',\n",
       " 'cg00819310',\n",
       " 'cg00819362',\n",
       " 'cg00819696',\n",
       " 'cg00821764',\n",
       " 'cg00822607',\n",
       " 'cg00823148',\n",
       " 'cg00824109',\n",
       " 'cg00826384',\n",
       " 'cg00827369',\n",
       " 'cg00828602',\n",
       " 'cg00830029',\n",
       " 'cg00830393',\n",
       " 'cg00831028',\n",
       " 'cg00832517',\n",
       " 'cg00833393',\n",
       " 'cg00834958',\n",
       " 'cg00836605',\n",
       " 'cg00837103',\n",
       " 'cg00838150',\n",
       " 'cg00839584',\n",
       " 'cg00839802',\n",
       " 'cg00840403',\n",
       " 'cg00840516',\n",
       " 'cg00841581',\n",
       " 'cg00845900',\n",
       " 'cg00846036',\n",
       " 'cg00848394',\n",
       " 'cg00848397',\n",
       " 'cg00848728',\n",
       " 'cg00849368',\n",
       " 'cg00850538',\n",
       " 'cg00852964',\n",
       " 'cg00853068',\n",
       " 'cg00854637',\n",
       " 'cg00854995',\n",
       " 'cg00856375',\n",
       " 'cg00858899',\n",
       " 'cg00859193',\n",
       " 'cg00861635',\n",
       " 'cg00862290',\n",
       " 'cg00862770',\n",
       " 'cg00864867',\n",
       " 'cg00870662',\n",
       " 'cg00871453',\n",
       " 'cg00873037',\n",
       " 'cg00873937',\n",
       " 'cg00875272',\n",
       " 'cg00876704',\n",
       " 'cg00877887',\n",
       " 'cg00877964',\n",
       " 'cg00881086',\n",
       " 'cg00881370',\n",
       " 'cg00882451',\n",
       " 'cg00882832',\n",
       " 'cg00884221',\n",
       " 'cg00884529',\n",
       " 'cg00885506',\n",
       " 'cg00886554',\n",
       " 'cg00887101',\n",
       " 'cg00887547',\n",
       " 'cg00887700',\n",
       " 'cg00888007',\n",
       " 'cg00888479',\n",
       " 'cg00888561',\n",
       " 'cg00890257',\n",
       " 'cg00891278',\n",
       " 'cg00892798',\n",
       " 'cg00893242',\n",
       " 'cg00893636',\n",
       " 'cg00897329',\n",
       " 'cg00899086',\n",
       " 'cg00899641',\n",
       " 'cg00899659',\n",
       " 'cg00901493',\n",
       " 'cg00901652',\n",
       " 'cg00901683',\n",
       " 'cg00901704',\n",
       " 'cg00901766',\n",
       " 'cg00903242',\n",
       " 'cg00904483',\n",
       " 'cg00904574',\n",
       " 'cg00905170',\n",
       " 'cg00906183',\n",
       " 'cg00908551',\n",
       " 'cg00910067',\n",
       " 'cg00910168',\n",
       " 'cg00911873',\n",
       " 'cg00915289',\n",
       " 'cg00916199',\n",
       " 'cg00916635',\n",
       " 'cg00917893',\n",
       " 'cg00918794',\n",
       " 'cg00919857',\n",
       " 'cg00922727',\n",
       " 'cg00925229',\n",
       " 'cg00925717',\n",
       " 'cg00929606',\n",
       " 'cg00929855',\n",
       " 'cg00930078',\n",
       " 'cg00930194',\n",
       " 'cg00933411',\n",
       " 'cg00935388',\n",
       " 'cg00935430',\n",
       " 'cg00936626',\n",
       " 'cg00940278',\n",
       " 'cg00940891',\n",
       " 'cg00941229',\n",
       " 'cg00943245',\n",
       " 'cg00943909',\n",
       " 'cg00943950',\n",
       " 'cg00945507',\n",
       " 'cg00945862',\n",
       " 'cg00947019',\n",
       " 'cg00948524',\n",
       " 'cg00950418',\n",
       " 'cg00950621',\n",
       " 'cg00951770',\n",
       " 'cg00953256',\n",
       " 'cg00953277',\n",
       " 'cg00954003',\n",
       " 'cg00954566',\n",
       " 'cg00955230',\n",
       " 'cg00955451',\n",
       " 'cg00958517',\n",
       " 'cg00960702',\n",
       " 'cg00962459',\n",
       " 'cg00964109',\n",
       " 'cg00970325',\n",
       " 'cg00971396',\n",
       " 'cg00973286',\n",
       " 'cg00973334',\n",
       " 'cg00973677',\n",
       " 'cg00976054',\n",
       " 'cg00979348',\n",
       " 'cg00980978',\n",
       " 'cg00983520',\n",
       " 'cg00983899',\n",
       " 'cg00984602',\n",
       " 'cg00987015',\n",
       " 'cg00987379',\n",
       " 'cg00995065',\n",
       " 'cg00995152',\n",
       " 'cg00995327',\n",
       " 'cg00995520',\n",
       " 'cg01000094',\n",
       " 'cg01001286',\n",
       " 'cg01007201',\n",
       " 'cg01009664',\n",
       " 'cg01013324',\n",
       " 'cg01015871',\n",
       " 'cg01015879',\n",
       " 'cg01021485',\n",
       " 'cg01025842',\n",
       " 'cg01026744',\n",
       " 'cg01027739',\n",
       " 'cg01027805',\n",
       " 'cg01029592',\n",
       " 'cg01031251',\n",
       " 'cg01031400',\n",
       " 'cg01033160',\n",
       " 'cg01035238',\n",
       " 'cg01035422',\n",
       " 'cg01036148',\n",
       " 'cg01036173',\n",
       " 'cg01036779',\n",
       " 'cg01037108',\n",
       " 'cg01040062',\n",
       " 'cg01040759',\n",
       " 'cg01040850',\n",
       " 'cg01041367',\n",
       " 'cg01044662',\n",
       " 'cg01044722',\n",
       " 'cg01046174',\n",
       " 'cg01047414',\n",
       " 'cg01048931',\n",
       " 'cg01049530',\n",
       " 'cg01050433',\n",
       " 'cg01053621',\n",
       " 'cg01055695',\n",
       " 'cg01056568',\n",
       " 'cg01057962',\n",
       " 'cg01058368',\n",
       " 'cg01062029',\n",
       " 'cg01063524',\n",
       " 'cg01064307',\n",
       " 'cg01064957',\n",
       " 'cg01065920',\n",
       " 'cg01069256',\n",
       " 'cg01071811',\n",
       " 'cg01072821',\n",
       " 'cg01076838',\n",
       " 'cg01078276',\n",
       " 'cg01078434',\n",
       " 'cg01081263',\n",
       " 'cg01086895',\n",
       " 'cg01086978',\n",
       " 'cg01087382',\n",
       " 'cg01087710',\n",
       " 'cg01090445',\n",
       " 'cg01091448',\n",
       " 'cg01091565',\n",
       " 'cg01092036',\n",
       " 'cg01092561',\n",
       " 'cg01095590',\n",
       " 'cg01097940',\n",
       " 'cg01100784',\n",
       " 'cg01100796',\n",
       " 'cg01103730',\n",
       " 'cg01103836',\n",
       " 'cg01104423',\n",
       " 'cg01106788',\n",
       " 'cg01107031',\n",
       " 'cg01107741',\n",
       " 'cg01108476',\n",
       " 'cg01110312',\n",
       " 'cg01110846',\n",
       " 'cg01112778',\n",
       " 'cg01114088',\n",
       " 'cg01116966',\n",
       " 'cg01117627',\n",
       " 'cg01119135',\n",
       " 'cg01120165',\n",
       " 'cg01120307',\n",
       " 'cg01120308',\n",
       " 'cg01120898',\n",
       " 'cg01124420',\n",
       " 'cg01124961',\n",
       " 'cg01125463',\n",
       " 'cg01126560',\n",
       " 'cg01127428',\n",
       " 'cg01128603',\n",
       " 'cg01129459',\n",
       " 'cg01130192',\n",
       " 'cg01131735',\n",
       " 'cg01135200',\n",
       " 'cg01136458',\n",
       " 'cg01137065',\n",
       " 'cg01137198',\n",
       " 'cg01137532',\n",
       " 'cg01137708',\n",
       " 'cg01137737',\n",
       " 'cg01138020',\n",
       " 'cg01139059',\n",
       " 'cg01139966',\n",
       " 'cg01141769',\n",
       " 'cg01143454',\n",
       " 'cg01144286',\n",
       " 'cg01145389',\n",
       " 'cg01145396',\n",
       " 'cg01146980',\n",
       " 'cg01148741',\n",
       " 'cg01150454',\n",
       " 'cg01151686',\n",
       " 'cg01151699',\n",
       " 'cg01152019',\n",
       " 'cg01152499',\n",
       " 'cg01154193',\n",
       " 'cg01154537',\n",
       " 'cg01154775',\n",
       " 'cg01155039',\n",
       " 'cg01161216',\n",
       " 'cg01161597',\n",
       " 'cg01168201',\n",
       " 'cg01169610',\n",
       " 'cg01169624',\n",
       " 'cg01169726',\n",
       " 'cg01169778',\n",
       " 'cg01171588',\n",
       " 'cg01172656',\n",
       " 'cg01172735',\n",
       " 'cg01172899',\n",
       " 'cg01172972',\n",
       " 'cg01173186',\n",
       " 'cg01173291',\n",
       " 'cg01176271',\n",
       " 'cg01177524',\n",
       " 'cg01177956',\n",
       " 'cg01182585',\n",
       " 'cg01182697',\n",
       " 'cg01182873',\n",
       " 'cg01183669',\n",
       " 'cg01184449',\n",
       " 'cg01184522',\n",
       " 'cg01185080',\n",
       " 'cg01185754',\n",
       " 'cg01186777',\n",
       " 'cg01190915',\n",
       " 'cg01192900',\n",
       " 'cg01193293',\n",
       " 'cg01194444',\n",
       " 'cg01195053',\n",
       " 'cg01195127',\n",
       " 'cg01197831',\n",
       " 'cg01199721',\n",
       " 'cg01200060',\n",
       " 'cg01200177',\n",
       " 'cg01204271',\n",
       " 'cg01206472',\n",
       " 'cg01206970',\n",
       " 'cg01211097',\n",
       " 'cg01214321',\n",
       " 'cg01214847',\n",
       " 'cg01216369',\n",
       " 'cg01220033',\n",
       " 'cg01221484',\n",
       " 'cg01221637',\n",
       " 'cg01222684',\n",
       " 'cg01226811',\n",
       " 'cg01226883',\n",
       " 'cg01228636',\n",
       " 'cg01230160',\n",
       " 'cg01231779',\n",
       " 'cg01234063',\n",
       " 'cg01234133',\n",
       " 'cg01236137',\n",
       " 'cg01240931',\n",
       " 'cg01241375',\n",
       " 'cg01243790',\n",
       " 'cg01244871',\n",
       " 'cg01245595',\n",
       " 'cg01246405',\n",
       " 'cg01248426',\n",
       " 'cg01252496',\n",
       " 'cg01253107',\n",
       " 'cg01254459',\n",
       " 'cg01254505',\n",
       " 'cg01255349',\n",
       " 'cg01259619',\n",
       " 'cg01260219',\n",
       " 'cg01261503',\n",
       " 'cg01261535',\n",
       " 'cg01262913',\n",
       " 'cg01263716',\n",
       " 'cg01264826',\n",
       " 'cg01265637',\n",
       " 'cg01267315',\n",
       " 'cg01269048',\n",
       " 'cg01269795',\n",
       " 'cg01272601',\n",
       " 'cg01273150',\n",
       " 'cg01274324',\n",
       " 'cg01274660',\n",
       " 'cg01275830',\n",
       " 'cg01277844',\n",
       " 'cg01278291',\n",
       " 'cg01278696',\n",
       " 'cg01280080',\n",
       " 'cg01281904',\n",
       " 'cg01282074',\n",
       " 'cg01282432',\n",
       " 'cg01283289',\n",
       " 'cg01284306',\n",
       " 'cg01284619',\n",
       " 'cg01288067',\n",
       " 'cg01289103',\n",
       " 'cg01291404',\n",
       " 'cg01292265',\n",
       " 'cg01293143',\n",
       " 'cg01293647',\n",
       " 'cg01294695',\n",
       " 'cg01294702',\n",
       " 'cg01295203',\n",
       " 'cg01297972',\n",
       " 'cg01299496',\n",
       " 'cg01301664',\n",
       " 'cg01302245',\n",
       " 'cg01305421',\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21368"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpgpt_age']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cg00455876', 'cg01707559', 'cg03244189', 'cg03695421', 'cg04689676',\n",
       "       'cg04792227', 'cg04964672', 'cg13851368', 'cg14180491', 'cg14210405',\n",
       "       ...\n",
       "       'cg27532867', 'cg27534599', 'cg27536559', 'cg27545494', 'cg27552198',\n",
       "       'cg27553637', 'cg27575890', 'cg27585287', 'cg27592453', 'cg27598806'],\n",
       "      dtype='object', length=443206)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00455876</th>\n",
       "      <th>cg01707559</th>\n",
       "      <th>cg03244189</th>\n",
       "      <th>cg03695421</th>\n",
       "      <th>cg04689676</th>\n",
       "      <th>cg04792227</th>\n",
       "      <th>cg04964672</th>\n",
       "      <th>cg13851368</th>\n",
       "      <th>cg14180491</th>\n",
       "      <th>cg14210405</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27532867</th>\n",
       "      <th>cg27534599</th>\n",
       "      <th>cg27536559</th>\n",
       "      <th>cg27545494</th>\n",
       "      <th>cg27552198</th>\n",
       "      <th>cg27553637</th>\n",
       "      <th>cg27575890</th>\n",
       "      <th>cg27585287</th>\n",
       "      <th>cg27592453</th>\n",
       "      <th>cg27598806</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.352611</td>\n",
       "      <td>0.285023</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>0.317307</td>\n",
       "      <td>0.654633</td>\n",
       "      <td>0.354590</td>\n",
       "      <td>0.478328</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.777402</td>\n",
       "      <td>0.140125</td>\n",
       "      <td>0.049228</td>\n",
       "      <td>0.854127</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.377906</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.801194</td>\n",
       "      <td>0.876720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.317272</td>\n",
       "      <td>0.345102</td>\n",
       "      <td>0.435571</td>\n",
       "      <td>0.301970</td>\n",
       "      <td>0.346044</td>\n",
       "      <td>0.686608</td>\n",
       "      <td>0.455047</td>\n",
       "      <td>0.517205</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>0.758235</td>\n",
       "      <td>0.141635</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>0.838716</td>\n",
       "      <td>0.147395</td>\n",
       "      <td>0.427982</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.830896</td>\n",
       "      <td>0.831732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24654</th>\n",
       "      <td>0.364213</td>\n",
       "      <td>0.373167</td>\n",
       "      <td>0.383677</td>\n",
       "      <td>0.371633</td>\n",
       "      <td>0.400758</td>\n",
       "      <td>0.417855</td>\n",
       "      <td>0.709025</td>\n",
       "      <td>0.408174</td>\n",
       "      <td>0.521777</td>\n",
       "      <td>0.438885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>0.765001</td>\n",
       "      <td>0.236049</td>\n",
       "      <td>0.049031</td>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.097279</td>\n",
       "      <td>0.441205</td>\n",
       "      <td>0.053650</td>\n",
       "      <td>0.817943</td>\n",
       "      <td>0.848297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>0.645996</td>\n",
       "      <td>0.118774</td>\n",
       "      <td>0.109488</td>\n",
       "      <td>0.650313</td>\n",
       "      <td>0.073410</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>0.907011</td>\n",
       "      <td>0.842083</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>0.517147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053871</td>\n",
       "      <td>0.727399</td>\n",
       "      <td>0.181261</td>\n",
       "      <td>0.041696</td>\n",
       "      <td>0.846080</td>\n",
       "      <td>0.077593</td>\n",
       "      <td>0.353020</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.868281</td>\n",
       "      <td>0.872010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>0.393172</td>\n",
       "      <td>0.351914</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.432429</td>\n",
       "      <td>0.389742</td>\n",
       "      <td>0.377637</td>\n",
       "      <td>0.760646</td>\n",
       "      <td>0.465659</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.486697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.791954</td>\n",
       "      <td>0.221617</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.421793</td>\n",
       "      <td>0.055254</td>\n",
       "      <td>0.915611</td>\n",
       "      <td>0.863411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.097955</td>\n",
       "      <td>0.099898</td>\n",
       "      <td>0.712607</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.914319</td>\n",
       "      <td>0.820917</td>\n",
       "      <td>0.084572</td>\n",
       "      <td>0.525990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056571</td>\n",
       "      <td>0.800210</td>\n",
       "      <td>0.183646</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.862467</td>\n",
       "      <td>0.079173</td>\n",
       "      <td>0.367596</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.825740</td>\n",
       "      <td>0.884708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24702</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.087735</td>\n",
       "      <td>0.102858</td>\n",
       "      <td>0.757837</td>\n",
       "      <td>0.081985</td>\n",
       "      <td>0.140933</td>\n",
       "      <td>0.939900</td>\n",
       "      <td>0.802047</td>\n",
       "      <td>0.075081</td>\n",
       "      <td>0.469135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045415</td>\n",
       "      <td>0.786400</td>\n",
       "      <td>0.170066</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.881907</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>0.333335</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>0.874013</td>\n",
       "      <td>0.907831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>0.358957</td>\n",
       "      <td>0.377702</td>\n",
       "      <td>0.295379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195470</td>\n",
       "      <td>0.293281</td>\n",
       "      <td>0.684217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.775111</td>\n",
       "      <td>0.186350</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.837358</td>\n",
       "      <td>0.099946</td>\n",
       "      <td>0.385733</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>0.807588</td>\n",
       "      <td>0.869527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>0.407751</td>\n",
       "      <td>0.334039</td>\n",
       "      <td>0.364659</td>\n",
       "      <td>0.386185</td>\n",
       "      <td>0.342306</td>\n",
       "      <td>0.415866</td>\n",
       "      <td>0.753173</td>\n",
       "      <td>0.414093</td>\n",
       "      <td>0.482597</td>\n",
       "      <td>0.372852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044422</td>\n",
       "      <td>0.770602</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.038365</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>0.395870</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.883756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19268</th>\n",
       "      <td>0.655632</td>\n",
       "      <td>0.075540</td>\n",
       "      <td>0.106677</td>\n",
       "      <td>0.733518</td>\n",
       "      <td>0.077993</td>\n",
       "      <td>0.147640</td>\n",
       "      <td>0.914338</td>\n",
       "      <td>0.823746</td>\n",
       "      <td>0.087397</td>\n",
       "      <td>0.465290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>0.781196</td>\n",
       "      <td>0.167518</td>\n",
       "      <td>0.042034</td>\n",
       "      <td>0.845079</td>\n",
       "      <td>0.086865</td>\n",
       "      <td>0.354646</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.853569</td>\n",
       "      <td>0.827940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows Ã— 443206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00455876  cg01707559  cg03244189  cg03695421  cg04689676  \\\n",
       "sample_id                                                               \n",
       "13515        0.373903    0.352611    0.285023    0.343865    0.209481   \n",
       "4892         0.472144    0.317272    0.345102    0.435571    0.301970   \n",
       "24654        0.364213    0.373167    0.383677    0.371633    0.400758   \n",
       "8276         0.645996    0.118774    0.109488    0.650313    0.073410   \n",
       "23495        0.393172    0.351914    0.389313    0.432429    0.389742   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "7786         0.607018    0.097955    0.099898    0.712607    0.087751   \n",
       "24702        0.574336    0.087735    0.102858    0.757837    0.081985   \n",
       "11354        0.358957    0.377702    0.295379         NaN    0.195470   \n",
       "5197         0.407751    0.334039    0.364659    0.386185    0.342306   \n",
       "19268        0.655632    0.075540    0.106677    0.733518    0.077993   \n",
       "\n",
       "           cg04792227  cg04964672  cg13851368  cg14180491  cg14210405  ...  \\\n",
       "sample_id                                                              ...   \n",
       "13515        0.317307    0.654633    0.354590    0.478328    0.361801  ...   \n",
       "4892         0.346044    0.686608    0.455047    0.517205    0.399917  ...   \n",
       "24654        0.417855    0.709025    0.408174    0.521777    0.438885  ...   \n",
       "8276         0.202634    0.907011    0.842083    0.103456    0.517147  ...   \n",
       "23495        0.377637    0.760646    0.465659    0.482143    0.486697  ...   \n",
       "...               ...         ...         ...         ...         ...  ...   \n",
       "7786         0.176667    0.914319    0.820917    0.084572    0.525990  ...   \n",
       "24702        0.140933    0.939900    0.802047    0.075081    0.469135  ...   \n",
       "11354        0.293281    0.684217         NaN    0.553361         NaN  ...   \n",
       "5197         0.415866    0.753173    0.414093    0.482597    0.372852  ...   \n",
       "19268        0.147640    0.914338    0.823746    0.087397    0.465290  ...   \n",
       "\n",
       "           cg27532867  cg27534599  cg27536559  cg27545494  cg27552198  \\\n",
       "sample_id                                                               \n",
       "13515        0.059121    0.777402    0.140125    0.049228    0.854127   \n",
       "4892         0.061810    0.758235    0.141635    0.057578    0.838716   \n",
       "24654        0.064607    0.765001    0.236049    0.049031    0.848972   \n",
       "8276         0.053871    0.727399    0.181261    0.041696    0.846080   \n",
       "23495        0.055474    0.791954    0.221617    0.032351    0.859742   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "7786         0.056571    0.800210    0.183646    0.046256    0.862467   \n",
       "24702        0.045415    0.786400    0.170066    0.038829    0.881907   \n",
       "11354        0.063208    0.775111    0.186350    0.055446    0.837358   \n",
       "5197         0.044422    0.770602    0.199192    0.038365    0.851601   \n",
       "19268        0.053155    0.781196    0.167518    0.042034    0.845079   \n",
       "\n",
       "           cg27553637  cg27575890  cg27585287  cg27592453  cg27598806  \n",
       "sample_id                                                              \n",
       "13515        0.103806    0.377906    0.046019    0.801194    0.876720  \n",
       "4892         0.147395    0.427982    0.055870    0.830896    0.831732  \n",
       "24654        0.097279    0.441205    0.053650    0.817943    0.848297  \n",
       "8276         0.077593    0.353020    0.047327    0.868281    0.872010  \n",
       "23495        0.078798    0.421793    0.055254    0.915611    0.863411  \n",
       "...               ...         ...         ...         ...         ...  \n",
       "7786         0.079173    0.367596    0.049488    0.825740    0.884708  \n",
       "24702        0.086947    0.333335    0.045368    0.874013    0.907831  \n",
       "11354        0.099946    0.385733    0.042444    0.807588    0.869527  \n",
       "5197         0.077326    0.395870    0.043853    0.864127    0.883756  \n",
       "19268        0.086865    0.354646    0.040517    0.853569    0.827940  \n",
       "\n",
       "[474 rows x 443206 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00105470</th>\n",
       "      <th>cg00290506</th>\n",
       "      <th>cg00476580</th>\n",
       "      <th>cg00565688</th>\n",
       "      <th>cg00630164</th>\n",
       "      <th>cg00650762</th>\n",
       "      <th>cg00712898</th>\n",
       "      <th>cg00930078</th>\n",
       "      <th>cg00941229</th>\n",
       "      <th>cg01419479</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27118809</th>\n",
       "      <th>cg27158143</th>\n",
       "      <th>cg27187881</th>\n",
       "      <th>cg27195224</th>\n",
       "      <th>cg27281093</th>\n",
       "      <th>cg27324619</th>\n",
       "      <th>cg27378424</th>\n",
       "      <th>cg27416437</th>\n",
       "      <th>cg27501458</th>\n",
       "      <th>cg27532722</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>0.066271</td>\n",
       "      <td>0.168158</td>\n",
       "      <td>0.069540</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.081303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099306</td>\n",
       "      <td>0.080736</td>\n",
       "      <td>0.096607</td>\n",
       "      <td>0.824138</td>\n",
       "      <td>0.325251</td>\n",
       "      <td>0.751577</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.202823</td>\n",
       "      <td>0.796264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.024410</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.104483</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>0.061989</td>\n",
       "      <td>0.048411</td>\n",
       "      <td>0.058582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104458</td>\n",
       "      <td>0.085971</td>\n",
       "      <td>0.176423</td>\n",
       "      <td>0.778738</td>\n",
       "      <td>0.350453</td>\n",
       "      <td>0.728809</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.098191</td>\n",
       "      <td>0.205745</td>\n",
       "      <td>0.709666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24654</th>\n",
       "      <td>0.039425</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.062770</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.053491</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.043913</td>\n",
       "      <td>0.053572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.166130</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.307506</td>\n",
       "      <td>0.713916</td>\n",
       "      <td>0.079062</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.182273</td>\n",
       "      <td>0.775308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>0.037447</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>0.122843</td>\n",
       "      <td>0.065978</td>\n",
       "      <td>0.046319</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>0.049748</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>0.063004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070244</td>\n",
       "      <td>0.156625</td>\n",
       "      <td>0.134149</td>\n",
       "      <td>0.803444</td>\n",
       "      <td>0.290696</td>\n",
       "      <td>0.736893</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.052951</td>\n",
       "      <td>0.168628</td>\n",
       "      <td>0.835507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>0.029510</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.065447</td>\n",
       "      <td>0.129075</td>\n",
       "      <td>0.067116</td>\n",
       "      <td>0.043318</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.037853</td>\n",
       "      <td>0.040459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075782</td>\n",
       "      <td>0.065043</td>\n",
       "      <td>0.101919</td>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.324285</td>\n",
       "      <td>0.775781</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>0.054367</td>\n",
       "      <td>0.178012</td>\n",
       "      <td>0.821515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00105470  cg00290506  cg00476580  cg00565688  cg00630164  \\\n",
       "sample_id                                                               \n",
       "13515        0.027791    0.036983    0.066271    0.168158    0.069540   \n",
       "4892         0.024410    0.042328    0.104483    0.100738    0.068307   \n",
       "24654        0.039425    0.041783    0.077730    0.093721    0.062770   \n",
       "8276         0.037447    0.044743    0.085925    0.122843    0.065978   \n",
       "23495        0.029510    0.035749    0.065447    0.129075    0.067116   \n",
       "\n",
       "           cg00650762  cg00712898  cg00930078  cg00941229  cg01419479  ...  \\\n",
       "sample_id                                                              ...   \n",
       "13515        0.033915    0.043883    0.043430    0.049154    0.081303  ...   \n",
       "4892         0.042724    0.046198    0.061989    0.048411    0.058582  ...   \n",
       "24654        0.040048    0.053491    0.049444    0.043913    0.053572  ...   \n",
       "8276         0.046319    0.046198    0.049748    0.050062    0.063004  ...   \n",
       "23495        0.043318    0.051262    0.030788    0.037853    0.040459  ...   \n",
       "\n",
       "           cg27118809  cg27158143  cg27187881  cg27195224  cg27281093  \\\n",
       "sample_id                                                               \n",
       "13515        0.099306    0.080736    0.096607    0.824138    0.325251   \n",
       "4892         0.104458    0.085971    0.176423    0.778738    0.350453   \n",
       "24654        0.082414    0.060605    0.166130    0.812540    0.307506   \n",
       "8276         0.070244    0.156625    0.134149    0.803444    0.290696   \n",
       "23495        0.075782    0.065043    0.101919    0.782445    0.324285   \n",
       "\n",
       "           cg27324619  cg27378424  cg27416437  cg27501458  cg27532722  \n",
       "sample_id                                                              \n",
       "13515        0.751577    0.060099    0.070900    0.202823    0.796264  \n",
       "4892         0.728809    0.079687    0.098191    0.205745    0.709666  \n",
       "24654        0.713916    0.079062    0.059865    0.182273    0.775308  \n",
       "8276         0.736893    0.052130    0.052951    0.168628    0.835507  \n",
       "23495        0.775781    0.051840    0.054367    0.178012    0.821515  \n",
       "\n",
       "[5 rows x 21249 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filtered_df.loc[:, filtered_df.columns.isin(vocab['input'])]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00105470</th>\n",
       "      <th>cg00290506</th>\n",
       "      <th>cg00476580</th>\n",
       "      <th>cg00565688</th>\n",
       "      <th>cg00630164</th>\n",
       "      <th>cg00650762</th>\n",
       "      <th>cg00712898</th>\n",
       "      <th>cg00930078</th>\n",
       "      <th>cg00941229</th>\n",
       "      <th>cg01419479</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27118809</th>\n",
       "      <th>cg27158143</th>\n",
       "      <th>cg27187881</th>\n",
       "      <th>cg27195224</th>\n",
       "      <th>cg27281093</th>\n",
       "      <th>cg27324619</th>\n",
       "      <th>cg27378424</th>\n",
       "      <th>cg27416437</th>\n",
       "      <th>cg27501458</th>\n",
       "      <th>cg27532722</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>0.066271</td>\n",
       "      <td>0.168158</td>\n",
       "      <td>0.069540</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.081303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099306</td>\n",
       "      <td>0.080736</td>\n",
       "      <td>0.096607</td>\n",
       "      <td>0.824138</td>\n",
       "      <td>0.325251</td>\n",
       "      <td>0.751577</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.202823</td>\n",
       "      <td>0.796264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.024410</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.104483</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>0.061989</td>\n",
       "      <td>0.048411</td>\n",
       "      <td>0.058582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104458</td>\n",
       "      <td>0.085971</td>\n",
       "      <td>0.176423</td>\n",
       "      <td>0.778738</td>\n",
       "      <td>0.350453</td>\n",
       "      <td>0.728809</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.098191</td>\n",
       "      <td>0.205745</td>\n",
       "      <td>0.709666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24654</th>\n",
       "      <td>0.039425</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.062770</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.053491</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.043913</td>\n",
       "      <td>0.053572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.166130</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.307506</td>\n",
       "      <td>0.713916</td>\n",
       "      <td>0.079062</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.182273</td>\n",
       "      <td>0.775308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>0.037447</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>0.122843</td>\n",
       "      <td>0.065978</td>\n",
       "      <td>0.046319</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>0.049748</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>0.063004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070244</td>\n",
       "      <td>0.156625</td>\n",
       "      <td>0.134149</td>\n",
       "      <td>0.803444</td>\n",
       "      <td>0.290696</td>\n",
       "      <td>0.736893</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.052951</td>\n",
       "      <td>0.168628</td>\n",
       "      <td>0.835507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>0.029510</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.065447</td>\n",
       "      <td>0.129075</td>\n",
       "      <td>0.067116</td>\n",
       "      <td>0.043318</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.037853</td>\n",
       "      <td>0.040459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075782</td>\n",
       "      <td>0.065043</td>\n",
       "      <td>0.101919</td>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.324285</td>\n",
       "      <td>0.775781</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>0.054367</td>\n",
       "      <td>0.178012</td>\n",
       "      <td>0.821515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>0.035650</td>\n",
       "      <td>0.041770</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0.074692</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.048392</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>0.059791</td>\n",
       "      <td>0.059666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075886</td>\n",
       "      <td>0.070754</td>\n",
       "      <td>0.105584</td>\n",
       "      <td>0.805771</td>\n",
       "      <td>0.227886</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.069246</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.787051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24702</th>\n",
       "      <td>0.035340</td>\n",
       "      <td>0.045327</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.115242</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.065168</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>0.079971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070279</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>0.097797</td>\n",
       "      <td>0.786389</td>\n",
       "      <td>0.239924</td>\n",
       "      <td>0.771349</td>\n",
       "      <td>0.051317</td>\n",
       "      <td>0.054724</td>\n",
       "      <td>0.115677</td>\n",
       "      <td>0.810453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11354</th>\n",
       "      <td>0.031466</td>\n",
       "      <td>0.036925</td>\n",
       "      <td>0.094944</td>\n",
       "      <td>0.149997</td>\n",
       "      <td>0.052393</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.058376</td>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.042360</td>\n",
       "      <td>0.068223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068429</td>\n",
       "      <td>0.108781</td>\n",
       "      <td>0.120557</td>\n",
       "      <td>0.819198</td>\n",
       "      <td>0.228437</td>\n",
       "      <td>0.767523</td>\n",
       "      <td>0.060011</td>\n",
       "      <td>0.061483</td>\n",
       "      <td>0.155548</td>\n",
       "      <td>0.787109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>0.032759</td>\n",
       "      <td>0.053247</td>\n",
       "      <td>0.078296</td>\n",
       "      <td>0.126129</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.046702</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.087022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>0.078737</td>\n",
       "      <td>0.097086</td>\n",
       "      <td>0.800205</td>\n",
       "      <td>0.315281</td>\n",
       "      <td>0.732184</td>\n",
       "      <td>0.062989</td>\n",
       "      <td>0.063164</td>\n",
       "      <td>0.218542</td>\n",
       "      <td>0.788707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19268</th>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.044482</td>\n",
       "      <td>0.100631</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>0.059248</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.042460</td>\n",
       "      <td>0.042715</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073752</td>\n",
       "      <td>0.075007</td>\n",
       "      <td>0.115418</td>\n",
       "      <td>0.809136</td>\n",
       "      <td>0.193214</td>\n",
       "      <td>0.755224</td>\n",
       "      <td>0.072625</td>\n",
       "      <td>0.063633</td>\n",
       "      <td>0.144350</td>\n",
       "      <td>0.781497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows Ã— 21249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00105470  cg00290506  cg00476580  cg00565688  cg00630164  \\\n",
       "sample_id                                                               \n",
       "13515        0.027791    0.036983    0.066271    0.168158    0.069540   \n",
       "4892         0.024410    0.042328    0.104483    0.100738    0.068307   \n",
       "24654        0.039425    0.041783    0.077730    0.093721    0.062770   \n",
       "8276         0.037447    0.044743    0.085925    0.122843    0.065978   \n",
       "23495        0.029510    0.035749    0.065447    0.129075    0.067116   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "7786         0.035650    0.041770    0.065078    0.139177    0.074692   \n",
       "24702        0.035340    0.045327    0.063408    0.115242    0.072566   \n",
       "11354        0.031466    0.036925    0.094944    0.149997    0.052393   \n",
       "5197         0.032759    0.053247    0.078296    0.126129    0.042851   \n",
       "19268        0.024324    0.044482    0.100631    0.127097    0.059248   \n",
       "\n",
       "           cg00650762  cg00712898  cg00930078  cg00941229  cg01419479  ...  \\\n",
       "sample_id                                                              ...   \n",
       "13515        0.033915    0.043883    0.043430    0.049154    0.081303  ...   \n",
       "4892         0.042724    0.046198    0.061989    0.048411    0.058582  ...   \n",
       "24654        0.040048    0.053491    0.049444    0.043913    0.053572  ...   \n",
       "8276         0.046319    0.046198    0.049748    0.050062    0.063004  ...   \n",
       "23495        0.043318    0.051262    0.030788    0.037853    0.040459  ...   \n",
       "...               ...         ...         ...         ...         ...  ...   \n",
       "7786         0.050740    0.048392    0.045705    0.059791    0.059666  ...   \n",
       "24702        0.037346    0.065168    0.039956    0.056086    0.079971  ...   \n",
       "11354        0.032636    0.058376    0.052702    0.042360    0.068223  ...   \n",
       "5197         0.046702    0.053191    0.041976    0.044154    0.087022  ...   \n",
       "19268        0.042954    0.038043    0.042460    0.042715    0.053812  ...   \n",
       "\n",
       "           cg27118809  cg27158143  cg27187881  cg27195224  cg27281093  \\\n",
       "sample_id                                                               \n",
       "13515        0.099306    0.080736    0.096607    0.824138    0.325251   \n",
       "4892         0.104458    0.085971    0.176423    0.778738    0.350453   \n",
       "24654        0.082414    0.060605    0.166130    0.812540    0.307506   \n",
       "8276         0.070244    0.156625    0.134149    0.803444    0.290696   \n",
       "23495        0.075782    0.065043    0.101919    0.782445    0.324285   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "7786         0.075886    0.070754    0.105584    0.805771    0.227886   \n",
       "24702        0.070279    0.099391    0.097797    0.786389    0.239924   \n",
       "11354        0.068429    0.108781    0.120557    0.819198    0.228437   \n",
       "5197         0.087618    0.078737    0.097086    0.800205    0.315281   \n",
       "19268        0.073752    0.075007    0.115418    0.809136    0.193214   \n",
       "\n",
       "           cg27324619  cg27378424  cg27416437  cg27501458  cg27532722  \n",
       "sample_id                                                              \n",
       "13515        0.751577    0.060099    0.070900    0.202823    0.796264  \n",
       "4892         0.728809    0.079687    0.098191    0.205745    0.709666  \n",
       "24654        0.713916    0.079062    0.059865    0.182273    0.775308  \n",
       "8276         0.736893    0.052130    0.052951    0.168628    0.835507  \n",
       "23495        0.775781    0.051840    0.054367    0.178012    0.821515  \n",
       "...               ...         ...         ...         ...         ...  \n",
       "7786         0.724508    0.058492    0.069246    0.160121    0.787051  \n",
       "24702        0.771349    0.051317    0.054724    0.115677    0.810453  \n",
       "11354        0.767523    0.060011    0.061483    0.155548    0.787109  \n",
       "5197         0.732184    0.062989    0.063164    0.218542    0.788707  \n",
       "19268        0.755224    0.072625    0.063633    0.144350    0.781497  \n",
       "\n",
       "[474 rows x 21249 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/tutorials/raw/fhs_filtered.arrow'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARROW_DF_FILTERED_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_feather(ARROW_DF_FILTERED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Memory-Map Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform inference, we need to memory-map the data. This is done by using the `CpGPTDataSaver` class. We first need to define the `DNALLMEmbedder` and `IlluminaMethylationProber` classes, which contain the information about the DNA LLM Embeddings and the conversion between Illumina array probes to genomic locations, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mInitializing class DNALLMEmbedder.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mGenome files will be stored under ../dependencies/human/genomes.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mDNA embeddings will be stored under ../dependencies/human/dna_embeddings and subdirectories.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mEnsembl metadata dictionary loaded successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "embedder = DNALLMEmbedder(dependencies_dir=LLM_DEPENDENCIES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mIlluminaMethylationProber\u001b[0m: \u001b[1mInitializing class IlluminaMethylationProber.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mIlluminaMethylationProber\u001b[0m: \u001b[1mIllumina methylation manifest files will be stored under ../dependencies/human/manifests.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mIlluminaMethylationProber\u001b[0m: \u001b[1mIllumina metadata dictionary loaded successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prober = IlluminaMethylationProber(dependencies_dir=LLM_DEPENDENCIES_DIR, embedder=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cpgpt.data.components.illumina_methylation_prober.IlluminaMethylationProber at 0x7f9a49e28a90>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prober"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mInitializing class CpGPTDataSaver.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mDataset folders will be stored under ../data/tutorials/processed/fhs_setup.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mNo existing dataset metrics found. Please process files.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mNo existing genomic locations found. Please process files.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mStarting file processing.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d555b8c90b420f956bfd540bfec8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[33m\u001b[1mNo species column found. Defaulting to homo_sapiens.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mFile processing completed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define datasaver\n",
    "quick_setup_datasaver = CpGPTDataSaver(data_paths=ARROW_DF_FILTERED_PATH, processed_dir=PROCESSED_DIR)\n",
    "\n",
    "# Process the file\n",
    "quick_setup_datasaver.process_files(prober, embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Declare data module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define two data modules: one for the forward pass and reconstructing the methylation, and another one the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mInitializing class DNALLMEmbedder.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mGenome files will be stored under ../dependencies/human/genomes.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mDNA embeddings will be stored under ../dependencies/human/dna_embeddings and subdirectories.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mEnsembl metadata dictionary loaded successfully\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mInitializing class DNALLMEmbedder.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mGenome files will be stored under ../dependencies/human/genomes.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mDNA embeddings will be stored under ../dependencies/human/dna_embeddings and subdirectories.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mEnsembl metadata dictionary loaded successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define datamodule\n",
    "quick_setup_datamodule = CpGPTDataModule(\n",
    "    predict_dir=PROCESSED_DIR,\n",
    "    dependencies_dir=LLM_DEPENDENCIES_DIR,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    max_length=MAX_INPUT_LENGTH,\n",
    "    dna_llm=config.data.dna_llm,\n",
    "    dna_context_len=config.data.dna_context_len,\n",
    "    sorting_strategy=config.data.sorting_strategy,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "# Define datamodule\n",
    "quick_setup_datamodule_attn = CpGPTDataModule(\n",
    "    predict_dir=PROCESSED_DIR,\n",
    "    dependencies_dir=LLM_DEPENDENCIES_DIR,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    max_length=MAX_ATTN_LENGTH,\n",
    "    dna_llm=config.data.dna_llm,\n",
    "    dna_context_len=config.data.dna_context_len,\n",
    "    sorting_strategy=config.data.sorting_strategy,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to perform inference with CpGPT. Here, we'll go through the most common ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Declare Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all models were trained under mixed precision, we'll use the `precision=\"16-mixed\"` argument. However, if you finetune it using a different precision, you can change that accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = CpGPTTrainer(precision=\"16-mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get Sample Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8253dae4cc824b899a1a7238b809aa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:928\u001b[39m, in \u001b[36mTrainer._predict_impl\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[39m\n\u001b[32m    925\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    926\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    927\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1051\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:125\u001b[39m, in \u001b[36m_PredictionLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:255\u001b[39m, in \u001b[36m_PredictionLoop._predict_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    250\u001b[39m step_args = (\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, \u001b[33m\"\u001b[39m\u001b[33mpredict_step\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    254\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m predictions = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredict_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:438\u001b[39m, in \u001b[36mStrategy.predict_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mpredict_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/model/cpgpt_module.py:577\u001b[39m, in \u001b[36mCpGPTLitModule.predict_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, **kwargs)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     output_dictionary = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_forward_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    580\u001b[39m     \u001b[38;5;66;03m# Filter the dictionary to include only keys specified in return_keys\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/model/cpgpt_module.py:629\u001b[39m, in \u001b[36mCpGPTLitModule._predict_forward_step\u001b[39m\u001b[34m(self, batch, n_splits)\u001b[39m\n\u001b[32m    622\u001b[39m output_dictionary = {\n\u001b[32m    623\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmeth\u001b[39m\u001b[33m\"\u001b[39m: input_data[\u001b[33m\"\u001b[39m\u001b[33mmeth\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    624\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmask_na\u001b[39m\u001b[33m\"\u001b[39m: input_data[\u001b[33m\"\u001b[39m\u001b[33mmask_na\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    627\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpositions\u001b[39m\u001b[33m\"\u001b[39m: input_data[\u001b[33m\"\u001b[39m\u001b[33mpositions\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    628\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfull_sequence_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurrent_input_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/model/cpgpt_module.py:857\u001b[39m, in \u001b[36mCpGPTLitModule._forward_pass\u001b[39m\u001b[34m(self, batch, input_data, loss_inputs, full_sequence_embeddings, current_input_masks)\u001b[39m\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# Encode sample\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m sample_embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[38;5;66;03m# Add diffusion components if enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/model/components/model.py:447\u001b[39m, in \u001b[36mCpGPT.encode_sample\u001b[39m\u001b[34m(self, meth, sequence_embeddings, chroms, positions, mask_na)\u001b[39m\n\u001b[32m    442\u001b[39m     attn_mask = (\n\u001b[32m    443\u001b[39m         create_hic_attention_mask(chroms, positions, \u001b[38;5;28mself\u001b[39m.n_attention_heads)\n\u001b[32m    444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positional_encoding == \u001b[33m\"\u001b[39m\u001b[33mhic\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    445\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    446\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     cpg_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpg_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_na\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# Get sample embedding\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:517\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/model/components/modules.py:800\u001b[39m, in \u001b[36mTransformerPPBlock.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm_first:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     x_sa = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_split_norm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m     x = x + x_sa\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/model/components/modules.py:829\u001b[39m, in \u001b[36mTransformerPPBlock._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout_sa(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/modules/activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/functional.py:6230\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6227\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6228\u001b[39m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6229\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6230\u001b[39m     q, k, v = \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/torch/nn/functional.py:5614\u001b[39m, in \u001b[36m_in_projection_packed\u001b[39m\u001b[34m(q, k, v, w, b)\u001b[39m\n\u001b[32m   5612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[32m   5613\u001b[39m     \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5614\u001b[39m     proj = \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5615\u001b[39m     \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m quick_setup_sample_embeddings = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquick_setup_datamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredict_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msample_embedding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lus/grand/projects/GeomicVar/tarak/cpgpt/CpGPT/cpgpt/trainer/cpgpt_trainer.py:178\u001b[39m, in \u001b[36mCpGPTTrainer.predict\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(model, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_predict\u001b[39m\u001b[33m\"\u001b[39m, value)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Only pass the arguments that the parent predict method expects\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m predictions_list = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# Clean up the attributes we added\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:887\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    886\u001b[39m \u001b[38;5;28mself\u001b[39m.predicting = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/grand/GeomicVar/tarak/cpgpt/cpgpt_env/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "quick_setup_sample_embeddings = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"forward\",\n",
    "    return_keys=[\"sample_embedding\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_embedding': tensor([[-2.6272e-01, -7.3696e-02, -2.6239e-02,  ..., -9.3649e-02,\n",
       "          -3.6611e-02, -1.8364e-02],\n",
       "         [-3.0251e-01, -7.7571e-02, -5.5078e-02,  ..., -1.1866e-01,\n",
       "          -5.1626e-02, -2.7392e-03],\n",
       "         [-5.5322e-02,  1.3166e-03, -7.8424e-02,  ..., -3.0264e-02,\n",
       "          -1.0671e-02, -1.4953e-01],\n",
       "         ...,\n",
       "         [-2.0327e-01, -5.4256e-02, -7.8379e-02,  ..., -9.7128e-02,\n",
       "           3.3823e-02, -4.2534e-02],\n",
       "         [-2.3025e-01, -7.0735e-02, -6.5348e-02,  ..., -1.0442e-01,\n",
       "           1.2583e-02, -2.7886e-02],\n",
       "         [-2.0669e-01, -5.3605e-02, -1.0745e-01,  ..., -9.1940e-02,\n",
       "          -2.3419e-04, -7.1221e-02]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_sample_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sample_embedding'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_sample_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quick_setup_sample_embeddings['sample_embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Predict Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6701aaadf441ac991829def24e9af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_pred_conditions = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"forward\",\n",
    "    return_keys=[\"pred_conditions\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_conditions': tensor([[ 0.3667],\n",
       "         [ 0.0154],\n",
       "         [ 6.9766],\n",
       "         [ 0.4402],\n",
       "         [-0.6748],\n",
       "         [-0.2629],\n",
       "         [-0.7241],\n",
       "         [-2.7090],\n",
       "         [-0.1346],\n",
       "         [-0.4250],\n",
       "         [-0.0770],\n",
       "         [ 0.1849],\n",
       "         [-0.0803],\n",
       "         [ 0.4863],\n",
       "         [ 2.5410],\n",
       "         [-1.4512],\n",
       "         [-3.1914],\n",
       "         [ 3.1328],\n",
       "         [-0.7524],\n",
       "         [-1.4854],\n",
       "         [-1.8594],\n",
       "         [-1.4404],\n",
       "         [-2.0391],\n",
       "         [-1.4297],\n",
       "         [-2.4863],\n",
       "         [-2.0703],\n",
       "         [-2.4922],\n",
       "         [-2.4121],\n",
       "         [-2.3438],\n",
       "         [-1.7637],\n",
       "         [-1.4941],\n",
       "         [-2.4941],\n",
       "         [-0.4998],\n",
       "         [-0.5352],\n",
       "         [-1.9775],\n",
       "         [-3.3359],\n",
       "         [-1.0107],\n",
       "         [-0.5669]], dtype=torch.float16)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_pred_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Reconstruct Methylation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's get some the reconstructed methylation values for some locations of interest based on the Illumina probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cg00000292', 'cg00002426', 'cg00003994', 'cg00005847', 'cg00008493']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random probes for demonstration\n",
    "probes = list(df.columns[0:100])\n",
    "\n",
    "probes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16:28878778', '3:57757815', '7:15686236', '2:176164344', '14:93347430']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert probes to genomic locations\n",
    "genomic_locations = prober.locate_probes(probes, \"homo_sapiens\")\n",
    "\n",
    "genomic_locations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5295ca43bd854f46874501e6f1d6c4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_pred_meth = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"reconstruct\",\n",
    "    genomic_locations=genomic_locations,\n",
    "    species=\"homo_sapiens\",\n",
    "    return_keys=[\"pred_meth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be mindful as the reconstructed values are M values, not beta values. Therefore, you need to convert them to beta values using the `m_to_beta` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_meth': tensor([[0.8501, 0.8633, 0.0503,  ..., 0.0348, 0.9292, 0.7095],\n",
       "         [0.8706, 0.8833, 0.0492,  ..., 0.0340, 0.9419, 0.7275],\n",
       "         [0.3799, 0.4067, 0.2776,  ..., 0.3308, 0.4133, 0.2937],\n",
       "         ...,\n",
       "         [0.7925, 0.7881, 0.0529,  ..., 0.0367, 0.9351, 0.7075],\n",
       "         [0.8247, 0.8291, 0.0523,  ..., 0.0337, 0.9351, 0.7031],\n",
       "         [0.6494, 0.4927, 0.0576,  ..., 0.0337, 0.9385, 0.7085]],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_pred_meth[\"pred_meth\"] = m_to_beta(quick_setup_pred_meth[\"pred_meth\"])\n",
    "quick_setup_pred_meth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more powerful way of reconstructing the methylation values is using chain-of-thought. With additional test-time compute, we can let the model \"think harder\" about the problem, which can lead to better performance. However, it also takes considerably longer dependending on the number of thinking steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acc5665c097411682686d6c4e3e1eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_pred_meth_cot = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"reconstruct\",\n",
    "    genomic_locations=genomic_locations,\n",
    "    species=\"homo_sapiens\",\n",
    "    n_thinking_steps=5,\n",
    "    thinking_step_size=1000,\n",
    "    uncertainty_quantile=0.1,\n",
    "    return_keys=[\"pred_meth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_meth': tensor([[0.8516, 0.8486, 0.0482,  ..., 0.0344, 0.9248, 0.7080],\n",
       "         [0.8691, 0.8696, 0.0484,  ..., 0.0330, 0.9434, 0.7383],\n",
       "         [0.4485, 0.4104, 0.3074,  ..., 0.3823, 0.3540, 0.2976],\n",
       "         ...,\n",
       "         [0.7856, 0.7690, 0.0512,  ..., 0.0355, 0.9326, 0.6919],\n",
       "         [0.8271, 0.8198, 0.0520,  ..., 0.0332, 0.9331, 0.6934],\n",
       "         [0.6523, 0.4868, 0.0560,  ..., 0.0331, 0.9297, 0.7061]],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_pred_meth_cot[\"pred_meth\"] = m_to_beta(quick_setup_pred_meth_cot[\"pred_meth\"])\n",
    "quick_setup_pred_meth_cot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Analyze Attention Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of memory required to store the attention weights is enormous. Therefore, we only use 1000 features for the demonstration. Also, remember that the the first token is the CLS token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9ff4bf0f164c078749d80cd707aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_attn = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule_attn,\n",
    "    predict_mode=\"attention\",\n",
    "    aggregate_heads=\"mean\",\n",
    "    layer_index=-1,\n",
    "    return_keys=[\"attention_weights\", \"chroms\", \"positions\", \"mask_na\", \"meth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_weights': tensor([[[0.0011, 0.0010, 0.0009,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0011, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0121, 0.0115, 0.0097,  ...,    nan,    nan,    nan],\n",
       "          [0.0114, 0.0123, 0.0098,  ...,    nan,    nan,    nan],\n",
       "          [0.0105, 0.0110, 0.0222,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0011, 0.0011,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0011, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]]]),\n",
       " 'meth': tensor([[0.8164, 0.0323, 0.0501,  ...,    nan,    nan,    nan],\n",
       "         [0.9417, 0.0925, 0.0540,  ...,    nan,    nan,    nan],\n",
       "         [0.6220, 0.3588, 0.4511,  ...,    nan,    nan,    nan],\n",
       "         ...,\n",
       "         [0.1128, 0.0809, 0.1357,  ...,    nan,    nan,    nan],\n",
       "         [0.7781, 0.0938, 0.0571,  ...,    nan,    nan,    nan],\n",
       "         [0.0147, 0.6906, 0.6015,  ...,    nan,    nan,    nan]]),\n",
       " 'mask_na': tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]]),\n",
       " 'chroms': tensor([[ 2,  2,  2,  ..., -1, -1, -1],\n",
       "         [16, 16, 16,  ..., -1, -1, -1],\n",
       "         [ 0,  0,  0,  ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 2,  2,  2,  ..., -1, -1, -1],\n",
       "         [16, 16, 16,  ..., -1, -1, -1],\n",
       "         [ 7,  7,  7,  ..., -1, -1, -1]], dtype=torch.int32),\n",
       " 'positions': tensor([[  394198,   746800,  2140242,  ...,       -1,       -1,       -1],\n",
       "         [ 1394034,  2756719,  2964113,  ...,       -1,       -1,       -1],\n",
       "         [15410502, 24319359, 24902090,  ...,       -1,       -1,       -1],\n",
       "         ...,\n",
       "         [  451100,   536298,   805725,  ...,       -1,       -1,       -1],\n",
       "         [  625585,  1720432,  4859955,  ...,       -1,       -1,       -1],\n",
       "         [  234647,   276727,   689597,  ...,       -1,       -1,       -1]],\n",
       "        dtype=torch.int32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "quick_setup_attn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
